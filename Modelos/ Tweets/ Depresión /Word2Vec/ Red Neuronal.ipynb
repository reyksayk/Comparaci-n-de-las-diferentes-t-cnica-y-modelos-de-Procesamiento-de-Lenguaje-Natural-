{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1DrMHzYuDnEXtOGWiCAC0_hm4VVmHzfFG",
      "authorship_tag": "ABX9TyNisKeNhVTGtKd3C5aPfZPQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAZ8Fq9Jhgmq"
      },
      "outputs": [],
      "source": [
        "!pip install nltk\n",
        "!pip install spacy\n",
        "!python -m spacy download es_core_news_sm\n",
        "!pip install -U imbalanced-learn\n",
        "!pip install pyspellchecker"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "%matplotlib inline\n",
        "\n",
        "# Oculta warnings\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "metadata": {
        "id": "hcn6j7o3h6HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_ZWhvFDAiCFh",
        "outputId": "aaf09905-f37f-4f5a-ae56-fea1568e88a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:95% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CARGAR DATOS\n",
        "**DATOS DE ENTRENAMIENTO**\n",
        "\n",
        "la columna de trastornos indica si el TWEET es de una persona con depresión o es de control.\n",
        "\n",
        "\n",
        "**control**:     0\n",
        "\n",
        "**depresión**:   1"
      ],
      "metadata": {
        "id": "E_Lg6613iGTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ruta_archivo_entrenamiento = '/content/drive/MyDrive/Experimentación Python Tesis /entrenamiento y prueba/train.csv'\n",
        "data_train = pd.read_csv(ruta_archivo_entrenamiento, sep=',')\n",
        "data_train.info()\n",
        "data_train.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "MHBqymIkiK0G",
        "outputId": "9426356c-d876-474f-c810-285cd701ac40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 263950 entries, 0 to 263949\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   USER_ID     263950 non-null  object \n",
            " 1   TWEET_ID    263920 non-null  float64\n",
            " 2   TWEET_TEXT  263841 non-null  object \n",
            " 3   trastorno   263950 non-null  int64  \n",
            "dtypes: float64(1), int64(1), object(2)\n",
            "memory usage: 8.1+ MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  USER_ID      TWEET_ID                                         TWEET_TEXT  \\\n",
              "0      87  2.147484e+09  RT @Julii_AKD: por qué a la mayoría de las pib...   \n",
              "1       6  2.147484e+09                  Empezar un 2017 sintiéndote solo.   \n",
              "2     279  2.147484e+09  Ah mirá que lindo como me escrachan en Instagr...   \n",
              "3     518  2.147484e+09                            https://t.co/hC3rULMb1P   \n",
              "4     301  2.147484e+09  Tu sigue con él, cumple tu deber, muy pronto v...   \n",
              "5     177  2.147484e+09                  @Sebbasrp deje dormir al prójimo.   \n",
              "6      45  2.147484e+09  RT @Crookedgirlx: no quiero vivir más, estoy c...   \n",
              "7      29  2.147484e+09  RT @Esunbreakable: Me da un poquito de vergüen...   \n",
              "8     388  2.147484e+09  Venezuela-related Designation https://t.co/IOZ...   \n",
              "9      31  2.147484e+09  Tengo muchas ganas de escribirte para decirte ...   \n",
              "\n",
              "   trastorno  \n",
              "0          1  \n",
              "1          1  \n",
              "2          0  \n",
              "3          0  \n",
              "4          0  \n",
              "5          0  \n",
              "6          1  \n",
              "7          1  \n",
              "8          0  \n",
              "9          1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea1bb25f-06ad-4ef5-9032-1698727f0e44\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>USER_ID</th>\n",
              "      <th>TWEET_ID</th>\n",
              "      <th>TWEET_TEXT</th>\n",
              "      <th>trastorno</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>87</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>RT @Julii_AKD: por qué a la mayoría de las pib...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>Empezar un 2017 sintiéndote solo.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>279</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>Ah mirá que lindo como me escrachan en Instagr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>https://t.co/hC3rULMb1P</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>301</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>Tu sigue con él, cumple tu deber, muy pronto v...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>177</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>@Sebbasrp deje dormir al prójimo.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>45</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>RT @Crookedgirlx: no quiero vivir más, estoy c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>29</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>RT @Esunbreakable: Me da un poquito de vergüen...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>388</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>Venezuela-related Designation https://t.co/IOZ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>31</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>Tengo muchas ganas de escribirte para decirte ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea1bb25f-06ad-4ef5-9032-1698727f0e44')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ea1bb25f-06ad-4ef5-9032-1698727f0e44 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ea1bb25f-06ad-4ef5-9032-1698727f0e44');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e2109d60-acf8-454f-a3c2-93fd6324e89c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e2109d60-acf8-454f-a3c2-93fd6324e89c')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e2109d60-acf8-454f-a3c2-93fd6324e89c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DATOS DE PRUEBA"
      ],
      "metadata": {
        "id": "YE5B35uviasR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_docs = 500"
      ],
      "metadata": {
        "id": "rGlAqL-JlMVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ruta_archivo_entrenamiento = '/content/drive/MyDrive/Experimentación Python Tesis /entrenamiento y prueba/train.csv'\n",
        "data_train = pd.read_csv(ruta_archivo_entrenamiento, sep=',')\n",
        "#data = pd.read_csv(ruta_archivo_entrenamiento, sep=',')\n",
        "#data_train = data.iloc[:num_docs, :]\n",
        "data_train.info()\n",
        "data_train.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "z4OAFdgOieHw",
        "outputId": "ee616019-a7df-45a9-e1bd-d16e1a5edfa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 263950 entries, 0 to 263949\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   USER_ID     263950 non-null  object \n",
            " 1   TWEET_ID    263920 non-null  float64\n",
            " 2   TWEET_TEXT  263841 non-null  object \n",
            " 3   trastorno   263950 non-null  int64  \n",
            "dtypes: float64(1), int64(1), object(2)\n",
            "memory usage: 8.1+ MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  USER_ID      TWEET_ID                                         TWEET_TEXT  \\\n",
              "0      87  2.147484e+09  RT @Julii_AKD: por qué a la mayoría de las pib...   \n",
              "1       6  2.147484e+09                  Empezar un 2017 sintiéndote solo.   \n",
              "2     279  2.147484e+09  Ah mirá que lindo como me escrachan en Instagr...   \n",
              "3     518  2.147484e+09                            https://t.co/hC3rULMb1P   \n",
              "4     301  2.147484e+09  Tu sigue con él, cumple tu deber, muy pronto v...   \n",
              "5     177  2.147484e+09                  @Sebbasrp deje dormir al prójimo.   \n",
              "6      45  2.147484e+09  RT @Crookedgirlx: no quiero vivir más, estoy c...   \n",
              "7      29  2.147484e+09  RT @Esunbreakable: Me da un poquito de vergüen...   \n",
              "8     388  2.147484e+09  Venezuela-related Designation https://t.co/IOZ...   \n",
              "9      31  2.147484e+09  Tengo muchas ganas de escribirte para decirte ...   \n",
              "\n",
              "   trastorno  \n",
              "0          1  \n",
              "1          1  \n",
              "2          0  \n",
              "3          0  \n",
              "4          0  \n",
              "5          0  \n",
              "6          1  \n",
              "7          1  \n",
              "8          0  \n",
              "9          1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e07b5c95-f3e5-49c2-8da4-622646055f1d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>USER_ID</th>\n",
              "      <th>TWEET_ID</th>\n",
              "      <th>TWEET_TEXT</th>\n",
              "      <th>trastorno</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>87</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>RT @Julii_AKD: por qué a la mayoría de las pib...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>Empezar un 2017 sintiéndote solo.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>279</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>Ah mirá que lindo como me escrachan en Instagr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>https://t.co/hC3rULMb1P</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>301</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>Tu sigue con él, cumple tu deber, muy pronto v...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>177</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>@Sebbasrp deje dormir al prójimo.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>45</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>RT @Crookedgirlx: no quiero vivir más, estoy c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>29</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>RT @Esunbreakable: Me da un poquito de vergüen...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>388</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>Venezuela-related Designation https://t.co/IOZ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>31</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>Tengo muchas ganas de escribirte para decirte ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e07b5c95-f3e5-49c2-8da4-622646055f1d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e07b5c95-f3e5-49c2-8da4-622646055f1d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e07b5c95-f3e5-49c2-8da4-622646055f1d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-94562856-1109-46b5-8a81-d3c210b75891\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94562856-1109-46b5-8a81-d3c210b75891')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-94562856-1109-46b5-8a81-d3c210b75891 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATOS DE PRUEBA (TEST)"
      ],
      "metadata": {
        "id": "aNX1Ab-W4frJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_docs_test = 5000"
      ],
      "metadata": {
        "id": "upPirSuq4xUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ruta_archivo_prueba = '/content/drive/MyDrive/Experimentación Python Tesis /entrenamiento y prueba/test.csv'\n",
        "# data_test = pd.read_csv(ruta_archivo_prueba, lineterminator='\\n')\n",
        "data_t = pd.read_csv(ruta_archivo_prueba, lineterminator='\\n')\n",
        "data_test =data_t.iloc[:num_docs_test, :]\n",
        "data_test.info()\n",
        "data_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "TD09x26j4wJu",
        "outputId": "dd7e83e7-08ea-411c-cef4-f992dcac76fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   USER_ID     5000 non-null   int64 \n",
            " 1   TWEET_ID    5000 non-null   int64 \n",
            " 2   TWEET_TEXT  5000 non-null   object\n",
            " 3   trastorno   5000 non-null   int64 \n",
            "dtypes: int64(3), object(1)\n",
            "memory usage: 156.4+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   USER_ID    TWEET_ID                                         TWEET_TEXT  \\\n",
              "0       30  2147483647  RT @Unicornio_Azul5: ¿Está mal desear estar mu...   \n",
              "1      508  2147483647  RT @tachame_ladoble: Esta noche!! Volvemos a V...   \n",
              "2      279  2147483647  RT @PsychdelicPics: Art by I Love Doodle https...   \n",
              "3       12  2147483647                   Hoy no he pasado de las 700kcal.   \n",
              "4      277  2147483647  RT @NetSportAcademy: Elisa Luque se proclama c...   \n",
              "\n",
              "   trastorno  \n",
              "0          1  \n",
              "1          0  \n",
              "2          0  \n",
              "3          1  \n",
              "4          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5b6017d-14ab-4f17-8e3c-217a07bf6f0b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>USER_ID</th>\n",
              "      <th>TWEET_ID</th>\n",
              "      <th>TWEET_TEXT</th>\n",
              "      <th>trastorno</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30</td>\n",
              "      <td>2147483647</td>\n",
              "      <td>RT @Unicornio_Azul5: ¿Está mal desear estar mu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>508</td>\n",
              "      <td>2147483647</td>\n",
              "      <td>RT @tachame_ladoble: Esta noche!! Volvemos a V...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>279</td>\n",
              "      <td>2147483647</td>\n",
              "      <td>RT @PsychdelicPics: Art by I Love Doodle https...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12</td>\n",
              "      <td>2147483647</td>\n",
              "      <td>Hoy no he pasado de las 700kcal.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>277</td>\n",
              "      <td>2147483647</td>\n",
              "      <td>RT @NetSportAcademy: Elisa Luque se proclama c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5b6017d-14ab-4f17-8e3c-217a07bf6f0b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b5b6017d-14ab-4f17-8e3c-217a07bf6f0b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b5b6017d-14ab-4f17-8e3c-217a07bf6f0b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7460f494-cacc-4211-9b3d-8fce11cf1202\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7460f494-cacc-4211-9b3d-8fce11cf1202')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7460f494-cacc-4211-9b3d-8fce11cf1202 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocesamiento de los datos"
      ],
      "metadata": {
        "id": "ptXa7Tu7ij05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')  #Solamente se ha de descargar la primera vez.\n",
        "stopwords_es = nltk.corpus.stopwords.words('spanish')   # Extrae las stopwords en español"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhwSBFjBjedd",
        "outputId": "992ff0b7-c46d-4e44-cde0-e8bbc6d40ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Eliminar etiquetas HTML*"
      ],
      "metadata": {
        "id": "qVqEoMoKipXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def removeHTML(text):\n",
        "    if isinstance(text, str):  # Verificar si es de tipo string\n",
        "        cleanr = re.compile('<.*?>')\n",
        "        cleantext = re.sub(cleanr, '', text)\n",
        "        return cleantext\n",
        "    else:\n",
        "        return text  # Devolver el valor original si no es de tipo string"
      ],
      "metadata": {
        "id": "KeumIo59iujw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Limpieza del texto*"
      ],
      "metadata": {
        "id": "d_94CnocizER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def clean(text):\n",
        "    if isinstance(text, str):  # Verificar si es de tipo string\n",
        "        # Eliminar hashtags\n",
        "        text = re.sub(r'#\\w+', '', text)\n",
        "\n",
        "        # Eliminar URLs o enlaces\n",
        "        text = re.sub(r'(https?://)?[a-zA-Z0-9]+\\.[a-zA-Z0-9]+\\S*', '', text)\n",
        "\n",
        "        # Eliminar nombres de usuarios de Twitter\n",
        "        text = re.sub(r'@\\w+', '', text)\n",
        "\n",
        "        # Eliminar Nombres propios\n",
        "        text = re.sub(r'\\b[A-Z][a-z]+\\b', '', text)\n",
        "\n",
        "        # Eliminar todos los caracteres especiales\n",
        "        text = re.sub(r'[^\\w\\s]+', '', text)\n",
        "\n",
        "        # Eliminar prefijos y números\n",
        "        text = re.sub(r'\\b\\w{1,2}\\b|\\d+', '', text)\n",
        "\n",
        "        # Eliminar palabras específicas\n",
        "        specific_words = ['retweet', 'retweets', 'hashtag', 'trending', 'mención', 'enlace', 'emoji', 'timeline', 'interacciones',\n",
        "                          'tuit', 'seguidores', 'notificaciones', 'seguir', 'favorito', 'perfil', 'tendencia', 'influencer',\n",
        "                          'compartir', 'actualización', 'explorar', 'seguir', 'comunidad', 'contenido', 'popular',\n",
        "                          'recomendar', 'experiencia', 'conectar', 'comentar', 'compartir', 'comunidad', 'actualización',\n",
        "                          'drk', 'followers', 'stats', 'for', 'new', 'little', 'unfollower', 'unfollowers', 'today', 'shit','twitter','nombre',\n",
        "                          'eric','story','great', 'short','squeeze','piggly','wiggly','hmv','even','follas','you','i','he','she',\n",
        "                          'it','we','they','the','and','that','these','those','tweet','followed','follower']\n",
        "        text = ' '.join([word for word in text.split() if word not in specific_words])\n",
        "\n",
        "        # Eliminar emojis\n",
        "        emojis = re.findall(r'[^\\w\\s,]', text)\n",
        "        cleaned_emojis = [emoji for emoji in emojis if emoji not in ['@', '#', '/', '?','¿','.','…','\"',':','“','!','¡','°','-',\"‘\",'’',\n",
        "                                                                     '=',';','(',')',\"'\",\"'\",'&','€','%','$','*','+','|', '”','🇦','🇷',',',\n",
        "                                                                     ', ','—','«',' »','»','« ','[, ]','[,]',',',', ','',' ',' ♀',' 🏽']]\n",
        "        for emoji in cleaned_emojis:\n",
        "            text = text.replace(emoji, '')\n",
        "\n",
        "        # Convertir el texto a minúsculas\n",
        "        text = text.lower()\n",
        "\n",
        "        # Eliminar signos de puntuación\n",
        "        text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
        "        # Tokenizar el texto en palabras\n",
        "        words = text.split()\n",
        "\n",
        "        # Eliminar palabras vacías\n",
        "        words = [word for word in words if word not in stopwords_es]\n",
        "\n",
        "        # Reconstruir el texto limpio\n",
        "        text = ' '.join(words)\n",
        "\n",
        "        # Devuelve el texto limpio\n",
        "        return text\n",
        "    else:\n",
        "        return text  # Devolver el valor original si no es de tipo string"
      ],
      "metadata": {
        "id": "ZiTpRUU6ixfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "483t5rwci40O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*lematizar y extraer términos*"
      ],
      "metadata": {
        "id": "ntVe2k6TkgPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.lang.es import Spanish\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "# Cargar modelo de spaCy\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "\n",
        "# Cargar stopwords en español\n",
        "stopwords_es = set(stopwords.words('spanish'))\n",
        "def extractTerms(text):\n",
        "    if isinstance(text, str):\n",
        "        # Tokenización y lematización con spaCy\n",
        "        doc = nlp(text)\n",
        "        lemmatized_terms = [token.lemma_ for token in doc if token.text.lower() not in stopwords_es]\n",
        "\n",
        "        return lemmatized_terms\n",
        "    else:\n",
        "        return []  # Devolver una lista vacía si el texto no es una cadena de texto\n",
        "\n",
        "# Ejemplo de uso\n",
        "texto_ejemplo = \"Los gatos están saltando sobre las vallas\"\n",
        "terminos_extraidos = extractTerms(texto_ejemplo)\n",
        "print(terminos_extraidos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfY-KveTkhye",
        "outputId": "5068c9f1-4f1b-4786-c06a-a77ce15eef9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['gato', 'saltar', 'valla']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesamieto del conjunto de datos de entrenamiento"
      ],
      "metadata": {
        "id": "_G1-6-J0kvNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train['TWEET_TEXT'] = data_train['TWEET_TEXT'].apply(removeHTML)\n",
        "data_train['TWEET_TEXT'] = data_train['TWEET_TEXT'].apply(clean)\n",
        "data_train['TWEET_TEXT'] = data_train['TWEET_TEXT'].apply(extractTerms)\n",
        "data_train.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "m-jc-AGMkyl7",
        "outputId": "0418a25e-bc4b-437a-d12a-d172c95afdb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  USER_ID      TWEET_ID                                         TWEET_TEXT  \\\n",
              "0      87  2.147484e+09  [mayoría, piba, gustar, tener, pierna, grande,...   \n",
              "1       6  2.147484e+09                                [sintiéndote, solo]   \n",
              "2     279  2.147484e+09                [mier, lindo, escrachan, magnifico]   \n",
              "3     518  2.147484e+09                                                 []   \n",
              "4     301  2.147484e+09  [seguir, cumple, deber, pronto, vestido, novia...   \n",
              "5     177  2.147484e+09                           [dejar, dormir, prójimo]   \n",
              "6      45  2.147484e+09                           [querer, vivir, cansado]   \n",
              "7      29  2.147484e+09  [poquito, vergüenza, alguien, querer, alzar yo...   \n",
              "8     388  2.147484e+09                                          [related]   \n",
              "9      31  2.147484e+09  [mucho, gana, escribirtar, decirte, extraño, d...   \n",
              "\n",
              "   trastorno  \n",
              "0          1  \n",
              "1          1  \n",
              "2          0  \n",
              "3          0  \n",
              "4          0  \n",
              "5          0  \n",
              "6          1  \n",
              "7          1  \n",
              "8          0  \n",
              "9          1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58fb2750-de79-4c2c-b8a7-27c535c6a28d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>USER_ID</th>\n",
              "      <th>TWEET_ID</th>\n",
              "      <th>TWEET_TEXT</th>\n",
              "      <th>trastorno</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>87</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>[mayoría, piba, gustar, tener, pierna, grande,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>[sintiéndote, solo]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>279</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>[mier, lindo, escrachan, magnifico]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>518</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>301</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>[seguir, cumple, deber, pronto, vestido, novia...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>177</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>[dejar, dormir, prójimo]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>45</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>[querer, vivir, cansado]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>29</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>[poquito, vergüenza, alguien, querer, alzar yo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>388</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>[related]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>31</td>\n",
              "      <td>2.147484e+09</td>\n",
              "      <td>[mucho, gana, escribirtar, decirte, extraño, d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58fb2750-de79-4c2c-b8a7-27c535c6a28d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58fb2750-de79-4c2c-b8a7-27c535c6a28d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58fb2750-de79-4c2c-b8a7-27c535c6a28d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5aed521d-0a14-4494-987b-19fcc21ee567\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5aed521d-0a14-4494-987b-19fcc21ee567')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5aed521d-0a14-4494-987b-19fcc21ee567 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar si hay elementos vacíos en la columna 'TWEET_TEXT'\n",
        "empty_count = (data_train['TWEET_TEXT'].apply(len) == 0).sum()\n",
        "\n",
        "# Imprimir el número de elementos vacíos en la columna 'TWEET_TEXT'\n",
        "print(\"Número de elementos vacíos en la columna 'TWEET_TEXT':\", empty_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkfJwuJalr6H",
        "outputId": "1f699807-8dc0-422a-e2cd-5187cb1fdc14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de elementos vacíos en la columna 'TWEET_TEXT': 17995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar filas donde 'TWEET_TEXT' no sea una lista vacía\n",
        "data_train = data_train[data_train['TWEET_TEXT'].apply(len) > 0]\n",
        "\n",
        "# Reiniciar el índice del DataFrame después de eliminar filas\n",
        "data_train.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "wr1meiHXluWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar si hay elementos vacíos en la columna 'TWEET_TEXT'\n",
        "empty_count = (data_train['TWEET_TEXT'].apply(len) == 0).sum()\n",
        "\n",
        "# Imprimir el número de elementos vacíos en la columna 'TWEET_TEXT'\n",
        "print(\"Número de elementos vacíos en la columna 'TWEET_TEXT':\", empty_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j2qM6y4lvG4",
        "outputId": "4e7f2e3e-8589-4092-883c-b5a939b6d451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de elementos vacíos en la columna 'TWEET_TEXT': 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spellchecker import SpellChecker\n",
        "\n",
        "def corrector_ortografico(tokens):\n",
        "    spell = SpellChecker(language='es')\n",
        "    tokens_corregidos = [spell.correction(token) if spell.correction(token) is not None else token for token in tokens]\n",
        "    return tokens_corregidos\n",
        "\n",
        "def corregir_palabras_largas(tokens):\n",
        "    tokens_corregidos = []\n",
        "    for token in tokens:\n",
        "        # Corregir repeticiones de letras\n",
        "        token_corregido = re.sub(r'(.)\\1+', r'\\1\\1', token)\n",
        "\n",
        "        # Corregir alargamiento de palabras\n",
        "        token_corregido = re.sub(r'(\\w)\\1{2,}', r'\\1\\1', token_corregido)\n",
        "\n",
        "        # Eliminar vocales repetidas más de 2 veces seguidas\n",
        "        token_corregido = re.sub(r'([aeiouáéíóú]{2,})\\1+', r'\\1', token_corregido, flags=re.IGNORECASE)\n",
        "\n",
        "        tokens_corregidos.append(token_corregido)\n",
        "    return tokens_corregidos\n"
      ],
      "metadata": {
        "id": "OWsQy3FWb-d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train['TWEET_TEXT'] = data_train['TWEET_TEXT'].apply(corregir_palabras_largas)\n",
        "data_train['TWEET_TEXT'] = data_train['TWEET_TEXT'].apply(corrector_ortografico)\n",
        "data_train.info()\n",
        "data_train.head(10)"
      ],
      "metadata": {
        "id": "JSpD-C-1cB5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Representación de los datos\n",
        "\n",
        "La caracterización de texto mediente Embedding transforma cada palabra del contexto en un vector de embedding.\n",
        "\n"
      ],
      "metadata": {
        "id": "p41SB9h6p_Eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "# Entrena un modelo Word2Vec usando CBOW\n",
        "modelW = Word2Vec(data_train['TWEET_TEXT'], vector_size=300, window=5, min_count=1, sg=0)# - vector_size: el tamaño de los vectores de palabra\n",
        "# - window: el tamaño de la ventana de contexto\n",
        "# - min_count: el número mínimo de veces que una palabra debe aparecer para ser considerada\n",
        "# - sg: 0 para CBOW, 1 para Skip-gram\n",
        "\n",
        "# Obtener la representación vectorial de un documento promediando las palabras\n",
        "def document_vector(tokens, modelW):\n",
        "    # Filtrar palabras que no están en el modelo\n",
        "    tokens = [token for token in tokens if token in modelW.wv.key_to_index]\n",
        "    if len(tokens) == 0:\n",
        "        return np.zeros(modelW.vector_size)\n",
        "    return np.mean([modelW.wv[token] for token in tokens], axis=0)\n",
        "\n",
        "# Crear una matriz de características X utilizando las representaciones vectoriales de Word2Vec\n",
        "X = [document_vector(tokens, modelW) for tokens in data_train['TWEET_TEXT']]\n",
        "\n",
        "# Obtener las etiquetas y\n",
        "y = data_train['trastorno'].values\n",
        "\n",
        "# Ahora puedes usar X e y para entrenar tu modelo de clasificación como se mencionó anteriormente"
      ],
      "metadata": {
        "id": "fBQWGrKoqAMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimimos el la longitud de las palabras totales\n",
        "print(modelW)\n",
        "print(len(modelW.wv))\n",
        "# Observamos el vocabulario creado\n",
        "words = modelW.wv.index_to_key\n",
        "print(words)"
      ],
      "metadata": {
        "id": "kJMqrbvVuM0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener la representación vectorial de una palabra específica\n",
        "vector = modelW.wv['depresión']\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCyf0k8Ardp9",
        "outputId": "6c6e03fc-7b02-4b1b-be7a-e98f4ffac264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.757954  ,  0.45204026,  0.06721898,  0.4468536 ,  0.32039365,\n",
              "       -0.5715685 , -0.14032412,  0.99840534, -0.77751833,  0.19518355,\n",
              "       -0.17098652, -0.5229607 ,  0.3393444 ,  0.670903  ,  0.33226073,\n",
              "       -1.1341778 ,  1.5154934 , -1.1948111 , -0.24898967, -1.4801852 ,\n",
              "        1.079218  ,  0.5614213 , -0.02628592, -1.6106755 ,  0.3910848 ,\n",
              "       -0.26012784, -1.0636528 , -0.67311233, -1.6267773 , -1.0026938 ,\n",
              "        0.6656351 ,  0.43395066, -0.118244  , -1.0220712 ,  0.3404876 ,\n",
              "        1.5123111 , -0.87018263, -0.22596519, -1.4198852 , -0.56338733,\n",
              "       -0.78556603, -0.17292719, -0.41425917,  0.21879858, -0.19536325,\n",
              "       -0.7293532 , -0.51317286, -0.7430189 ,  0.39923298,  1.3462886 ,\n",
              "        1.3828415 ,  0.7272359 , -1.2832279 ,  0.19451837, -0.55822027,\n",
              "       -0.7461571 , -0.26793456,  0.10697709, -0.64010006,  1.1539632 ,\n",
              "        0.11392349,  0.36736333, -0.7033996 ,  0.04602199, -1.0152628 ,\n",
              "        0.61277276,  0.3388784 ,  0.5188819 , -0.817934  ,  1.4967287 ,\n",
              "       -0.8075772 , -0.11699028,  0.7618389 , -0.6980649 ,  1.2003788 ,\n",
              "        0.21442246,  0.37558228,  0.20789133,  0.05228016, -0.00331304,\n",
              "       -1.2944443 , -0.19561511, -0.9891647 ,  1.7679119 , -0.5460142 ,\n",
              "       -0.9593282 , -0.26938087,  1.3666521 ,  0.32540768,  0.27813178,\n",
              "        1.104348  ,  0.8390625 ,  0.07995903,  0.16333547,  0.7425581 ,\n",
              "       -0.17731167,  1.0376385 , -0.2965967 ,  0.6760206 , -0.5023952 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aprensizaje del modelo: Red Neuronal\n",
        "**Validación Cruzada K=10**"
      ],
      "metadata": {
        "id": "YR_1UCCjz4Iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#  X es una lista de representaciones vectoriales Word2Vec y y son las etiquetas (0 o 1)\n",
        "X = X  # Aquí, X ya contiene las representaciones vectoriales de Word2Vec\n",
        "y = np.array(y)\n",
        "\n",
        "# Realizar balanceo si es necesario (oversampling)\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "X, y = oversampler.fit_resample(X, y)\n",
        "\n",
        "# Ahora, X y y tienen el mismo número de muestras\n",
        "\n",
        "# Convertir la lista de listas X_train en una matriz NumPy\n",
        "X = np.array(X)\n",
        "\n",
        "# Definir la estrategia de validación cruzada (k=10)\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para almacenar métricas de entrenamiento y validación\n",
        "train_accuracy_scores = []\n",
        "train_precision_scores = []\n",
        "train_recall_scores = []\n",
        "train_f1_scores = []\n",
        "\n",
        "val_accuracy_scores = []\n",
        "val_precision_scores = []\n",
        "val_recall_scores = []\n",
        "val_f1_scores = []\n",
        "\n",
        "# Realizar la validación cruzada\n",
        "for train_index, val_index in cv.split(X, y):\n",
        "    train_index, val_index = train_index.tolist(), val_index.tolist()  # Convertir a listas\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    # Crear una red neuronal secuencial para cada fold (reiniciar el modelo)\n",
        "    model = Sequential()\n",
        "\n",
        "    # Agregar una capa de entrada con el tamaño de los vectores Word2Vec\n",
        "    input_dim = len(X_train[0])  # Obtener la longitud de un vector Word2Vec\n",
        "    model.add(Dense(350, activation='relu', input_dim=input_dim))\n",
        "    model.add(Dropout(0.3))  # Dropout para regularización\n",
        "\n",
        "    # Agregar una capa oculta\n",
        "    model.add(Dense(228, activation='relu'))\n",
        "    model.add(Dropout(0.3))  # Dropout para regularización\n",
        "\n",
        "    # Agregar una capa de salida con una neurona y función de activación sigmoide para clasificación binaria\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compilar el modelo\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    # Utilizar EarlyStopping para detener el entrenamiento si no hay mejora\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Entrenar el modelo en los datos de entrenamiento del pliegue actual\n",
        "    model.fit(X_train, y_train, epochs=1000, batch_size=200, verbose=1, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "    # Evaluar el modelo en el conjunto de entrenamiento del pliegue actual\n",
        "    y_train_pred = (model.predict(X_train) > 0.5).astype(int)\n",
        "\n",
        "    # Calcular métricas de entrenamiento y agregarlas a las listas\n",
        "    train_accuracy_scores.append(accuracy_score(y_train, y_train_pred))\n",
        "    train_precision_scores.append(precision_score(y_train, y_train_pred))\n",
        "    train_recall_scores.append(recall_score(y_train, y_train_pred))\n",
        "    train_f1_scores.append(f1_score(y_train, y_train_pred))\n",
        "\n",
        "    # Evaluar el modelo en el conjunto de validación\n",
        "    y_val_pred = (model.predict(X_val) > 0.5).astype(int)\n",
        "\n",
        "    # Calcular métricas de validación y agregarlas a las listas\n",
        "    val_accuracy_scores.append(accuracy_score(y_val, y_val_pred))\n",
        "    val_precision_scores.append(precision_score(y_val, y_val_pred))\n",
        "    val_recall_scores.append(recall_score(y_val, y_val_pred))\n",
        "    val_f1_scores.append(f1_score(y_val, y_val_pred))\n",
        "\n",
        "# Calcular las métricas promediadas en entrenamiento\n",
        "train_accuracy_mean = np.mean(train_accuracy_scores)\n",
        "train_precision_mean = np.mean(train_precision_scores)\n",
        "train_recall_mean = np.mean(train_recall_scores)\n",
        "train_f1_mean = np.mean(train_f1_scores)\n",
        "\n",
        "# Calcular las métricas promediadas en validación\n",
        "val_accuracy_mean = np.mean(val_accuracy_scores)\n",
        "val_precision_mean = np.mean(val_precision_scores)\n",
        "val_recall_mean = np.mean(val_recall_scores)\n",
        "val_f1_mean = np.mean(val_f1_scores)\n",
        "\n",
        "# Imprimir las métricas promediadas en entrenamiento y validación\n",
        "print(\"Entrenamiento - Accuracy: {:.2f}%\".format(100 * train_accuracy_mean))\n",
        "print(\"Entrenamiento - Precision: {:.2f}%\".format(100 * train_precision_mean))\n",
        "print(\"Entrenamiento - Recall: {:.2f}%\".format(100 * train_recall_mean))\n",
        "print(\"Entrenamiento - F1 Score: {:.2f}%\".format(100 * train_f1_mean))\n",
        "\n",
        "print(\"Validación - Accuracy: {:.2f}%\".format(100 * val_accuracy_mean))\n",
        "print(\"Validación - Precision: {:.2f}%\".format(100 * val_precision_mean))\n",
        "print(\"Validación - Recall: {:.2f}%\".format(100 * val_recall_mean))\n",
        "print(\"Validación - F1 Score: {:.2f}%\".format(100 * val_f1_mean))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwLFtp2J2Xaz",
        "outputId": "a6447df6-1ed2-4da3-f1fd-5a623b1f3dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1125/1125 [==============================] - 8s 6ms/step - loss: 0.5389 - accuracy: 0.7242 - val_loss: 0.5209 - val_accuracy: 0.7309\n",
            "Epoch 2/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5253 - accuracy: 0.7309 - val_loss: 0.5184 - val_accuracy: 0.7344\n",
            "Epoch 3/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5217 - accuracy: 0.7338 - val_loss: 0.5123 - val_accuracy: 0.7372\n",
            "Epoch 4/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5193 - accuracy: 0.7348 - val_loss: 0.5110 - val_accuracy: 0.7378\n",
            "Epoch 5/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5175 - accuracy: 0.7353 - val_loss: 0.5125 - val_accuracy: 0.7373\n",
            "Epoch 6/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5160 - accuracy: 0.7365 - val_loss: 0.5084 - val_accuracy: 0.7415\n",
            "Epoch 7/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5146 - accuracy: 0.7372 - val_loss: 0.5103 - val_accuracy: 0.7401\n",
            "Epoch 8/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5134 - accuracy: 0.7382 - val_loss: 0.5074 - val_accuracy: 0.7407\n",
            "Epoch 9/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5129 - accuracy: 0.7381 - val_loss: 0.5059 - val_accuracy: 0.7400\n",
            "Epoch 10/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5119 - accuracy: 0.7392 - val_loss: 0.5049 - val_accuracy: 0.7408\n",
            "Epoch 11/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5108 - accuracy: 0.7390 - val_loss: 0.5068 - val_accuracy: 0.7403\n",
            "Epoch 12/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5103 - accuracy: 0.7401 - val_loss: 0.5056 - val_accuracy: 0.7404\n",
            "Epoch 13/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5089 - accuracy: 0.7402 - val_loss: 0.5043 - val_accuracy: 0.7435\n",
            "Epoch 14/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5085 - accuracy: 0.7413 - val_loss: 0.5069 - val_accuracy: 0.7423\n",
            "Epoch 15/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5078 - accuracy: 0.7412 - val_loss: 0.5060 - val_accuracy: 0.7402\n",
            "Epoch 16/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5071 - accuracy: 0.7418 - val_loss: 0.5050 - val_accuracy: 0.7420\n",
            "Epoch 17/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5067 - accuracy: 0.7422 - val_loss: 0.5049 - val_accuracy: 0.7421\n",
            "Epoch 18/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5058 - accuracy: 0.7420 - val_loss: 0.5035 - val_accuracy: 0.7429\n",
            "Epoch 19/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5052 - accuracy: 0.7425 - val_loss: 0.5070 - val_accuracy: 0.7406\n",
            "Epoch 20/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5045 - accuracy: 0.7435 - val_loss: 0.5042 - val_accuracy: 0.7417\n",
            "Epoch 21/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5034 - accuracy: 0.7437 - val_loss: 0.5062 - val_accuracy: 0.7443\n",
            "Epoch 22/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5035 - accuracy: 0.7442 - val_loss: 0.5013 - val_accuracy: 0.7430\n",
            "Epoch 23/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5030 - accuracy: 0.7441 - val_loss: 0.5048 - val_accuracy: 0.7420\n",
            "Epoch 24/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5022 - accuracy: 0.7448 - val_loss: 0.5035 - val_accuracy: 0.7436\n",
            "Epoch 25/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5019 - accuracy: 0.7443 - val_loss: 0.5037 - val_accuracy: 0.7436\n",
            "Epoch 26/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5016 - accuracy: 0.7461 - val_loss: 0.5015 - val_accuracy: 0.7437\n",
            "Epoch 27/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5012 - accuracy: 0.7450 - val_loss: 0.5025 - val_accuracy: 0.7438\n",
            "Epoch 28/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5007 - accuracy: 0.7458 - val_loss: 0.5004 - val_accuracy: 0.7465\n",
            "Epoch 29/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4998 - accuracy: 0.7457 - val_loss: 0.5032 - val_accuracy: 0.7421\n",
            "Epoch 30/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4997 - accuracy: 0.7462 - val_loss: 0.5013 - val_accuracy: 0.7448\n",
            "Epoch 31/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4995 - accuracy: 0.7470 - val_loss: 0.5005 - val_accuracy: 0.7436\n",
            "Epoch 32/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4990 - accuracy: 0.7467 - val_loss: 0.5001 - val_accuracy: 0.7441\n",
            "Epoch 33/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4982 - accuracy: 0.7472 - val_loss: 0.4998 - val_accuracy: 0.7458\n",
            "Epoch 34/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4979 - accuracy: 0.7476 - val_loss: 0.5035 - val_accuracy: 0.7432\n",
            "Epoch 35/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4979 - accuracy: 0.7478 - val_loss: 0.5023 - val_accuracy: 0.7445\n",
            "Epoch 36/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4973 - accuracy: 0.7473 - val_loss: 0.5000 - val_accuracy: 0.7440\n",
            "Epoch 37/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4964 - accuracy: 0.7483 - val_loss: 0.5010 - val_accuracy: 0.7435\n",
            "Epoch 38/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4961 - accuracy: 0.7486 - val_loss: 0.5001 - val_accuracy: 0.7457\n",
            "Epoch 39/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4957 - accuracy: 0.7485 - val_loss: 0.5000 - val_accuracy: 0.7436\n",
            "Epoch 40/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4958 - accuracy: 0.7484 - val_loss: 0.5012 - val_accuracy: 0.7442\n",
            "Epoch 41/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4948 - accuracy: 0.7491 - val_loss: 0.4994 - val_accuracy: 0.7436\n",
            "Epoch 42/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4949 - accuracy: 0.7494 - val_loss: 0.4997 - val_accuracy: 0.7432\n",
            "Epoch 43/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4949 - accuracy: 0.7492 - val_loss: 0.4997 - val_accuracy: 0.7448\n",
            "Epoch 44/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4941 - accuracy: 0.7499 - val_loss: 0.5007 - val_accuracy: 0.7441\n",
            "Epoch 45/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4941 - accuracy: 0.7502 - val_loss: 0.5007 - val_accuracy: 0.7453\n",
            "Epoch 46/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4934 - accuracy: 0.7497 - val_loss: 0.4982 - val_accuracy: 0.7460\n",
            "Epoch 47/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4934 - accuracy: 0.7507 - val_loss: 0.5000 - val_accuracy: 0.7464\n",
            "Epoch 48/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4925 - accuracy: 0.7516 - val_loss: 0.4992 - val_accuracy: 0.7440\n",
            "Epoch 49/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4924 - accuracy: 0.7512 - val_loss: 0.5007 - val_accuracy: 0.7454\n",
            "Epoch 50/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4922 - accuracy: 0.7516 - val_loss: 0.5007 - val_accuracy: 0.7434\n",
            "Epoch 51/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4919 - accuracy: 0.7516 - val_loss: 0.5045 - val_accuracy: 0.7410\n",
            "Epoch 52/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4916 - accuracy: 0.7516 - val_loss: 0.5014 - val_accuracy: 0.7464\n",
            "Epoch 53/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4911 - accuracy: 0.7522 - val_loss: 0.4998 - val_accuracy: 0.7452\n",
            "Epoch 54/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4908 - accuracy: 0.7527 - val_loss: 0.4982 - val_accuracy: 0.7466\n",
            "Epoch 55/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4903 - accuracy: 0.7523 - val_loss: 0.5010 - val_accuracy: 0.7462\n",
            "Epoch 56/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4905 - accuracy: 0.7518 - val_loss: 0.5011 - val_accuracy: 0.7450\n",
            "7028/7028 [==============================] - 11s 1ms/step\n",
            "781/781 [==============================] - 1s 1ms/step\n",
            "Epoch 1/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5382 - accuracy: 0.7241 - val_loss: 0.5296 - val_accuracy: 0.7271\n",
            "Epoch 2/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5248 - accuracy: 0.7317 - val_loss: 0.5220 - val_accuracy: 0.7335\n",
            "Epoch 3/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5207 - accuracy: 0.7332 - val_loss: 0.5223 - val_accuracy: 0.7302\n",
            "Epoch 4/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5178 - accuracy: 0.7353 - val_loss: 0.5243 - val_accuracy: 0.7335\n",
            "Epoch 5/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5166 - accuracy: 0.7362 - val_loss: 0.5182 - val_accuracy: 0.7363\n",
            "Epoch 6/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5145 - accuracy: 0.7374 - val_loss: 0.5170 - val_accuracy: 0.7352\n",
            "Epoch 7/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5133 - accuracy: 0.7384 - val_loss: 0.5172 - val_accuracy: 0.7359\n",
            "Epoch 8/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5125 - accuracy: 0.7390 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
            "Epoch 9/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5109 - accuracy: 0.7393 - val_loss: 0.5144 - val_accuracy: 0.7351\n",
            "Epoch 10/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5099 - accuracy: 0.7400 - val_loss: 0.5146 - val_accuracy: 0.7381\n",
            "Epoch 11/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5094 - accuracy: 0.7406 - val_loss: 0.5141 - val_accuracy: 0.7369\n",
            "Epoch 12/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5084 - accuracy: 0.7408 - val_loss: 0.5160 - val_accuracy: 0.7377\n",
            "Epoch 13/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5080 - accuracy: 0.7421 - val_loss: 0.5118 - val_accuracy: 0.7404\n",
            "Epoch 14/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5071 - accuracy: 0.7420 - val_loss: 0.5123 - val_accuracy: 0.7380\n",
            "Epoch 15/1000\n",
            "1125/1125 [==============================] - 9s 8ms/step - loss: 0.5063 - accuracy: 0.7426 - val_loss: 0.5123 - val_accuracy: 0.7390\n",
            "Epoch 16/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5054 - accuracy: 0.7431 - val_loss: 0.5122 - val_accuracy: 0.7377\n",
            "Epoch 17/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5044 - accuracy: 0.7435 - val_loss: 0.5121 - val_accuracy: 0.7398\n",
            "Epoch 18/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5043 - accuracy: 0.7429 - val_loss: 0.5106 - val_accuracy: 0.7395\n",
            "Epoch 19/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5038 - accuracy: 0.7436 - val_loss: 0.5106 - val_accuracy: 0.7391\n",
            "Epoch 20/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5027 - accuracy: 0.7445 - val_loss: 0.5116 - val_accuracy: 0.7382\n",
            "Epoch 21/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5025 - accuracy: 0.7445 - val_loss: 0.5115 - val_accuracy: 0.7380\n",
            "Epoch 22/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5020 - accuracy: 0.7448 - val_loss: 0.5098 - val_accuracy: 0.7402\n",
            "Epoch 23/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5019 - accuracy: 0.7454 - val_loss: 0.5095 - val_accuracy: 0.7406\n",
            "Epoch 24/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5017 - accuracy: 0.7455 - val_loss: 0.5112 - val_accuracy: 0.7392\n",
            "Epoch 25/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5008 - accuracy: 0.7456 - val_loss: 0.5117 - val_accuracy: 0.7397\n",
            "Epoch 26/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5003 - accuracy: 0.7461 - val_loss: 0.5096 - val_accuracy: 0.7400\n",
            "Epoch 27/1000\n",
            "1125/1125 [==============================] - 9s 8ms/step - loss: 0.4996 - accuracy: 0.7463 - val_loss: 0.5110 - val_accuracy: 0.7402\n",
            "Epoch 28/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4996 - accuracy: 0.7469 - val_loss: 0.5096 - val_accuracy: 0.7402\n",
            "Epoch 29/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4991 - accuracy: 0.7463 - val_loss: 0.5124 - val_accuracy: 0.7371\n",
            "Epoch 30/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4988 - accuracy: 0.7466 - val_loss: 0.5131 - val_accuracy: 0.7374\n",
            "Epoch 31/1000\n",
            "1125/1125 [==============================] - 8s 8ms/step - loss: 0.4982 - accuracy: 0.7477 - val_loss: 0.5086 - val_accuracy: 0.7415\n",
            "Epoch 32/1000\n",
            "1125/1125 [==============================] - 9s 8ms/step - loss: 0.4978 - accuracy: 0.7478 - val_loss: 0.5080 - val_accuracy: 0.7418\n",
            "Epoch 33/1000\n",
            "1125/1125 [==============================] - 11s 10ms/step - loss: 0.4973 - accuracy: 0.7484 - val_loss: 0.5093 - val_accuracy: 0.7417\n",
            "Epoch 34/1000\n",
            "1125/1125 [==============================] - 10s 9ms/step - loss: 0.4967 - accuracy: 0.7485 - val_loss: 0.5097 - val_accuracy: 0.7413\n",
            "Epoch 35/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4964 - accuracy: 0.7486 - val_loss: 0.5094 - val_accuracy: 0.7392\n",
            "Epoch 36/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4961 - accuracy: 0.7484 - val_loss: 0.5102 - val_accuracy: 0.7414\n",
            "Epoch 37/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4963 - accuracy: 0.7487 - val_loss: 0.5075 - val_accuracy: 0.7416\n",
            "Epoch 38/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4950 - accuracy: 0.7490 - val_loss: 0.5097 - val_accuracy: 0.7402\n",
            "Epoch 39/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4949 - accuracy: 0.7500 - val_loss: 0.5092 - val_accuracy: 0.7401\n",
            "Epoch 40/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4952 - accuracy: 0.7496 - val_loss: 0.5078 - val_accuracy: 0.7422\n",
            "Epoch 41/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4938 - accuracy: 0.7504 - val_loss: 0.5086 - val_accuracy: 0.7415\n",
            "Epoch 42/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4942 - accuracy: 0.7501 - val_loss: 0.5089 - val_accuracy: 0.7400\n",
            "Epoch 43/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4934 - accuracy: 0.7510 - val_loss: 0.5081 - val_accuracy: 0.7419\n",
            "Epoch 44/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4931 - accuracy: 0.7506 - val_loss: 0.5087 - val_accuracy: 0.7407\n",
            "Epoch 45/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4930 - accuracy: 0.7505 - val_loss: 0.5085 - val_accuracy: 0.7431\n",
            "Epoch 46/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4925 - accuracy: 0.7506 - val_loss: 0.5089 - val_accuracy: 0.7410\n",
            "Epoch 47/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4917 - accuracy: 0.7524 - val_loss: 0.5079 - val_accuracy: 0.7433\n",
            "7028/7028 [==============================] - 11s 2ms/step\n",
            "781/781 [==============================] - 1s 2ms/step\n",
            "Epoch 1/1000\n",
            "1125/1125 [==============================] - 9s 7ms/step - loss: 0.5389 - accuracy: 0.7244 - val_loss: 0.5226 - val_accuracy: 0.7285\n",
            "Epoch 2/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5251 - accuracy: 0.7316 - val_loss: 0.5265 - val_accuracy: 0.7315\n",
            "Epoch 3/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5215 - accuracy: 0.7335 - val_loss: 0.5198 - val_accuracy: 0.7360\n",
            "Epoch 4/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5188 - accuracy: 0.7351 - val_loss: 0.5144 - val_accuracy: 0.7357\n",
            "Epoch 5/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5178 - accuracy: 0.7356 - val_loss: 0.5121 - val_accuracy: 0.7385\n",
            "Epoch 6/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5160 - accuracy: 0.7365 - val_loss: 0.5111 - val_accuracy: 0.7370\n",
            "Epoch 7/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5140 - accuracy: 0.7379 - val_loss: 0.5132 - val_accuracy: 0.7384\n",
            "Epoch 8/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5132 - accuracy: 0.7383 - val_loss: 0.5102 - val_accuracy: 0.7377\n",
            "Epoch 9/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5124 - accuracy: 0.7393 - val_loss: 0.5115 - val_accuracy: 0.7378\n",
            "Epoch 10/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5120 - accuracy: 0.7392 - val_loss: 0.5093 - val_accuracy: 0.7397\n",
            "Epoch 11/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5100 - accuracy: 0.7393 - val_loss: 0.5082 - val_accuracy: 0.7402\n",
            "Epoch 12/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5100 - accuracy: 0.7400 - val_loss: 0.5091 - val_accuracy: 0.7388\n",
            "Epoch 13/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5089 - accuracy: 0.7413 - val_loss: 0.5092 - val_accuracy: 0.7383\n",
            "Epoch 14/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5078 - accuracy: 0.7407 - val_loss: 0.5081 - val_accuracy: 0.7377\n",
            "Epoch 15/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5072 - accuracy: 0.7412 - val_loss: 0.5083 - val_accuracy: 0.7402\n",
            "Epoch 16/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5071 - accuracy: 0.7417 - val_loss: 0.5057 - val_accuracy: 0.7398\n",
            "Epoch 17/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5058 - accuracy: 0.7424 - val_loss: 0.5045 - val_accuracy: 0.7428\n",
            "Epoch 18/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5051 - accuracy: 0.7423 - val_loss: 0.5071 - val_accuracy: 0.7400\n",
            "Epoch 19/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5051 - accuracy: 0.7432 - val_loss: 0.5044 - val_accuracy: 0.7425\n",
            "Epoch 20/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5039 - accuracy: 0.7433 - val_loss: 0.5049 - val_accuracy: 0.7430\n",
            "Epoch 21/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5033 - accuracy: 0.7431 - val_loss: 0.5087 - val_accuracy: 0.7438\n",
            "Epoch 22/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5036 - accuracy: 0.7433 - val_loss: 0.5077 - val_accuracy: 0.7414\n",
            "Epoch 23/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5026 - accuracy: 0.7438 - val_loss: 0.5051 - val_accuracy: 0.7422\n",
            "Epoch 24/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5022 - accuracy: 0.7444 - val_loss: 0.5041 - val_accuracy: 0.7446\n",
            "Epoch 25/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5017 - accuracy: 0.7445 - val_loss: 0.5034 - val_accuracy: 0.7435\n",
            "Epoch 26/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5011 - accuracy: 0.7452 - val_loss: 0.5047 - val_accuracy: 0.7432\n",
            "Epoch 27/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5003 - accuracy: 0.7465 - val_loss: 0.5038 - val_accuracy: 0.7425\n",
            "Epoch 28/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5000 - accuracy: 0.7458 - val_loss: 0.5018 - val_accuracy: 0.7450\n",
            "Epoch 29/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5002 - accuracy: 0.7461 - val_loss: 0.5040 - val_accuracy: 0.7428\n",
            "Epoch 30/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4992 - accuracy: 0.7463 - val_loss: 0.5051 - val_accuracy: 0.7442\n",
            "Epoch 31/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4990 - accuracy: 0.7454 - val_loss: 0.5032 - val_accuracy: 0.7424\n",
            "Epoch 32/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4988 - accuracy: 0.7471 - val_loss: 0.5021 - val_accuracy: 0.7455\n",
            "Epoch 33/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4981 - accuracy: 0.7477 - val_loss: 0.5038 - val_accuracy: 0.7456\n",
            "Epoch 34/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4975 - accuracy: 0.7480 - val_loss: 0.5043 - val_accuracy: 0.7428\n",
            "Epoch 35/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4967 - accuracy: 0.7480 - val_loss: 0.5030 - val_accuracy: 0.7429\n",
            "Epoch 36/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4968 - accuracy: 0.7484 - val_loss: 0.5050 - val_accuracy: 0.7432\n",
            "Epoch 37/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4967 - accuracy: 0.7489 - val_loss: 0.5038 - val_accuracy: 0.7444\n",
            "Epoch 38/1000\n",
            "1125/1125 [==============================] - 8s 8ms/step - loss: 0.4958 - accuracy: 0.7482 - val_loss: 0.5023 - val_accuracy: 0.7457\n",
            "7028/7028 [==============================] - 12s 2ms/step\n",
            "781/781 [==============================] - 1s 2ms/step\n",
            "Epoch 1/1000\n",
            "1125/1125 [==============================] - 9s 7ms/step - loss: 0.5392 - accuracy: 0.7251 - val_loss: 0.5198 - val_accuracy: 0.7336\n",
            "Epoch 2/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5262 - accuracy: 0.7311 - val_loss: 0.5262 - val_accuracy: 0.7261\n",
            "Epoch 3/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5218 - accuracy: 0.7333 - val_loss: 0.5112 - val_accuracy: 0.7393\n",
            "Epoch 4/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5192 - accuracy: 0.7350 - val_loss: 0.5122 - val_accuracy: 0.7404\n",
            "Epoch 5/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5175 - accuracy: 0.7356 - val_loss: 0.5087 - val_accuracy: 0.7384\n",
            "Epoch 6/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5161 - accuracy: 0.7360 - val_loss: 0.5090 - val_accuracy: 0.7406\n",
            "Epoch 7/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5148 - accuracy: 0.7374 - val_loss: 0.5055 - val_accuracy: 0.7400\n",
            "Epoch 8/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5136 - accuracy: 0.7382 - val_loss: 0.5077 - val_accuracy: 0.7401\n",
            "Epoch 9/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5125 - accuracy: 0.7389 - val_loss: 0.5068 - val_accuracy: 0.7426\n",
            "Epoch 10/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5114 - accuracy: 0.7392 - val_loss: 0.5041 - val_accuracy: 0.7408\n",
            "Epoch 11/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5109 - accuracy: 0.7394 - val_loss: 0.5070 - val_accuracy: 0.7412\n",
            "Epoch 12/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5098 - accuracy: 0.7404 - val_loss: 0.5046 - val_accuracy: 0.7399\n",
            "Epoch 13/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5088 - accuracy: 0.7413 - val_loss: 0.5023 - val_accuracy: 0.7435\n",
            "Epoch 14/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5085 - accuracy: 0.7410 - val_loss: 0.5032 - val_accuracy: 0.7412\n",
            "Epoch 15/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5076 - accuracy: 0.7420 - val_loss: 0.5073 - val_accuracy: 0.7435\n",
            "Epoch 16/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5075 - accuracy: 0.7417 - val_loss: 0.5057 - val_accuracy: 0.7422\n",
            "Epoch 17/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5061 - accuracy: 0.7423 - val_loss: 0.5058 - val_accuracy: 0.7407\n",
            "Epoch 18/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5065 - accuracy: 0.7423 - val_loss: 0.5052 - val_accuracy: 0.7398\n",
            "Epoch 19/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5052 - accuracy: 0.7429 - val_loss: 0.5035 - val_accuracy: 0.7429\n",
            "Epoch 20/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5053 - accuracy: 0.7427 - val_loss: 0.5015 - val_accuracy: 0.7427\n",
            "Epoch 21/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5040 - accuracy: 0.7436 - val_loss: 0.5019 - val_accuracy: 0.7412\n",
            "Epoch 22/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5038 - accuracy: 0.7439 - val_loss: 0.5069 - val_accuracy: 0.7404\n",
            "Epoch 23/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5031 - accuracy: 0.7441 - val_loss: 0.5012 - val_accuracy: 0.7424\n",
            "Epoch 24/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5027 - accuracy: 0.7446 - val_loss: 0.5003 - val_accuracy: 0.7421\n",
            "Epoch 25/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5019 - accuracy: 0.7454 - val_loss: 0.5003 - val_accuracy: 0.7439\n",
            "Epoch 26/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5017 - accuracy: 0.7454 - val_loss: 0.5002 - val_accuracy: 0.7441\n",
            "Epoch 27/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5015 - accuracy: 0.7455 - val_loss: 0.5022 - val_accuracy: 0.7408\n",
            "Epoch 28/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5010 - accuracy: 0.7460 - val_loss: 0.5028 - val_accuracy: 0.7436\n",
            "Epoch 29/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5005 - accuracy: 0.7461 - val_loss: 0.5026 - val_accuracy: 0.7432\n",
            "Epoch 30/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5001 - accuracy: 0.7462 - val_loss: 0.4985 - val_accuracy: 0.7448\n",
            "Epoch 31/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4995 - accuracy: 0.7463 - val_loss: 0.5011 - val_accuracy: 0.7434\n",
            "Epoch 32/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4992 - accuracy: 0.7463 - val_loss: 0.4981 - val_accuracy: 0.7451\n",
            "Epoch 33/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4987 - accuracy: 0.7471 - val_loss: 0.5023 - val_accuracy: 0.7430\n",
            "Epoch 34/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4990 - accuracy: 0.7470 - val_loss: 0.4990 - val_accuracy: 0.7415\n",
            "Epoch 35/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4977 - accuracy: 0.7477 - val_loss: 0.4998 - val_accuracy: 0.7452\n",
            "Epoch 36/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4978 - accuracy: 0.7477 - val_loss: 0.5005 - val_accuracy: 0.7441\n",
            "Epoch 37/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4971 - accuracy: 0.7483 - val_loss: 0.5005 - val_accuracy: 0.7435\n",
            "Epoch 38/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4968 - accuracy: 0.7480 - val_loss: 0.5001 - val_accuracy: 0.7414\n",
            "Epoch 39/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4961 - accuracy: 0.7483 - val_loss: 0.4997 - val_accuracy: 0.7472\n",
            "Epoch 40/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4956 - accuracy: 0.7494 - val_loss: 0.5003 - val_accuracy: 0.7454\n",
            "Epoch 41/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4960 - accuracy: 0.7489 - val_loss: 0.4999 - val_accuracy: 0.7431\n",
            "Epoch 42/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4951 - accuracy: 0.7498 - val_loss: 0.5007 - val_accuracy: 0.7450\n",
            "7028/7028 [==============================] - 13s 2ms/step\n",
            "781/781 [==============================] - 2s 2ms/step\n",
            "Epoch 1/1000\n",
            "1125/1125 [==============================] - 11s 7ms/step - loss: 0.5391 - accuracy: 0.7232 - val_loss: 0.5219 - val_accuracy: 0.7328\n",
            "Epoch 2/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5249 - accuracy: 0.7315 - val_loss: 0.5181 - val_accuracy: 0.7338\n",
            "Epoch 3/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5213 - accuracy: 0.7330 - val_loss: 0.5182 - val_accuracy: 0.7316\n",
            "Epoch 4/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5186 - accuracy: 0.7348 - val_loss: 0.5169 - val_accuracy: 0.7332\n",
            "Epoch 5/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5172 - accuracy: 0.7361 - val_loss: 0.5115 - val_accuracy: 0.7389\n",
            "Epoch 6/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5157 - accuracy: 0.7363 - val_loss: 0.5138 - val_accuracy: 0.7371\n",
            "Epoch 7/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5138 - accuracy: 0.7374 - val_loss: 0.5113 - val_accuracy: 0.7386\n",
            "Epoch 8/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5132 - accuracy: 0.7375 - val_loss: 0.5132 - val_accuracy: 0.7377\n",
            "Epoch 9/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5121 - accuracy: 0.7383 - val_loss: 0.5093 - val_accuracy: 0.7399\n",
            "Epoch 10/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5111 - accuracy: 0.7392 - val_loss: 0.5097 - val_accuracy: 0.7403\n",
            "Epoch 11/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5098 - accuracy: 0.7396 - val_loss: 0.5098 - val_accuracy: 0.7412\n",
            "Epoch 12/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5097 - accuracy: 0.7402 - val_loss: 0.5087 - val_accuracy: 0.7394\n",
            "Epoch 13/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5081 - accuracy: 0.7407 - val_loss: 0.5105 - val_accuracy: 0.7371\n",
            "Epoch 14/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5078 - accuracy: 0.7410 - val_loss: 0.5091 - val_accuracy: 0.7416\n",
            "Epoch 15/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5070 - accuracy: 0.7409 - val_loss: 0.5073 - val_accuracy: 0.7424\n",
            "Epoch 16/1000\n",
            "1125/1125 [==============================] - 9s 8ms/step - loss: 0.5068 - accuracy: 0.7413 - val_loss: 0.5076 - val_accuracy: 0.7422\n",
            "Epoch 17/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5059 - accuracy: 0.7419 - val_loss: 0.5086 - val_accuracy: 0.7422\n",
            "Epoch 18/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5052 - accuracy: 0.7426 - val_loss: 0.5071 - val_accuracy: 0.7405\n",
            "Epoch 19/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5045 - accuracy: 0.7431 - val_loss: 0.5073 - val_accuracy: 0.7442\n",
            "Epoch 20/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5039 - accuracy: 0.7430 - val_loss: 0.5086 - val_accuracy: 0.7430\n",
            "Epoch 21/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5036 - accuracy: 0.7433 - val_loss: 0.5049 - val_accuracy: 0.7430\n",
            "Epoch 22/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5035 - accuracy: 0.7434 - val_loss: 0.5044 - val_accuracy: 0.7430\n",
            "Epoch 23/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5023 - accuracy: 0.7447 - val_loss: 0.5079 - val_accuracy: 0.7412\n",
            "Epoch 24/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5015 - accuracy: 0.7448 - val_loss: 0.5042 - val_accuracy: 0.7428\n",
            "Epoch 25/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5014 - accuracy: 0.7454 - val_loss: 0.5068 - val_accuracy: 0.7434\n",
            "Epoch 26/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5011 - accuracy: 0.7446 - val_loss: 0.5062 - val_accuracy: 0.7442\n",
            "Epoch 27/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5012 - accuracy: 0.7450 - val_loss: 0.5045 - val_accuracy: 0.7436\n",
            "Epoch 28/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5002 - accuracy: 0.7459 - val_loss: 0.5052 - val_accuracy: 0.7425\n",
            "Epoch 29/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4994 - accuracy: 0.7463 - val_loss: 0.5043 - val_accuracy: 0.7428\n",
            "Epoch 30/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4996 - accuracy: 0.7462 - val_loss: 0.5051 - val_accuracy: 0.7450\n",
            "Epoch 31/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4988 - accuracy: 0.7462 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
            "Epoch 32/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4984 - accuracy: 0.7461 - val_loss: 0.5058 - val_accuracy: 0.7426\n",
            "Epoch 33/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4980 - accuracy: 0.7476 - val_loss: 0.5045 - val_accuracy: 0.7449\n",
            "Epoch 34/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4980 - accuracy: 0.7472 - val_loss: 0.5036 - val_accuracy: 0.7452\n",
            "Epoch 35/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4978 - accuracy: 0.7475 - val_loss: 0.5027 - val_accuracy: 0.7458\n",
            "Epoch 36/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4970 - accuracy: 0.7480 - val_loss: 0.5074 - val_accuracy: 0.7450\n",
            "Epoch 37/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4959 - accuracy: 0.7486 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 38/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4959 - accuracy: 0.7485 - val_loss: 0.5041 - val_accuracy: 0.7432\n",
            "Epoch 39/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4959 - accuracy: 0.7481 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
            "Epoch 40/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4954 - accuracy: 0.7495 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
            "Epoch 41/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4951 - accuracy: 0.7493 - val_loss: 0.5024 - val_accuracy: 0.7442\n",
            "Epoch 42/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4949 - accuracy: 0.7493 - val_loss: 0.5043 - val_accuracy: 0.7445\n",
            "Epoch 43/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4944 - accuracy: 0.7486 - val_loss: 0.5037 - val_accuracy: 0.7433\n",
            "Epoch 44/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4943 - accuracy: 0.7495 - val_loss: 0.5024 - val_accuracy: 0.7472\n",
            "Epoch 45/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4936 - accuracy: 0.7494 - val_loss: 0.5040 - val_accuracy: 0.7433\n",
            "Epoch 46/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4928 - accuracy: 0.7506 - val_loss: 0.5059 - val_accuracy: 0.7437\n",
            "Epoch 47/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4932 - accuracy: 0.7499 - val_loss: 0.5036 - val_accuracy: 0.7458\n",
            "Epoch 48/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4930 - accuracy: 0.7499 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
            "Epoch 49/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4926 - accuracy: 0.7497 - val_loss: 0.5025 - val_accuracy: 0.7468\n",
            "Epoch 50/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4920 - accuracy: 0.7504 - val_loss: 0.5031 - val_accuracy: 0.7468\n",
            "Epoch 51/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4921 - accuracy: 0.7513 - val_loss: 0.5035 - val_accuracy: 0.7456\n",
            "Epoch 52/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4911 - accuracy: 0.7516 - val_loss: 0.5038 - val_accuracy: 0.7442\n",
            "Epoch 53/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4906 - accuracy: 0.7515 - val_loss: 0.5037 - val_accuracy: 0.7470\n",
            "Epoch 54/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4912 - accuracy: 0.7507 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
            "7028/7028 [==============================] - 11s 2ms/step\n",
            "781/781 [==============================] - 1s 2ms/step\n",
            "Epoch 1/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5387 - accuracy: 0.7254 - val_loss: 0.5272 - val_accuracy: 0.7308\n",
            "Epoch 2/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5256 - accuracy: 0.7310 - val_loss: 0.5167 - val_accuracy: 0.7344\n",
            "Epoch 3/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5214 - accuracy: 0.7339 - val_loss: 0.5162 - val_accuracy: 0.7344\n",
            "Epoch 4/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5188 - accuracy: 0.7343 - val_loss: 0.5179 - val_accuracy: 0.7308\n",
            "Epoch 5/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5172 - accuracy: 0.7351 - val_loss: 0.5166 - val_accuracy: 0.7335\n",
            "Epoch 6/1000\n",
            "1125/1125 [==============================] - 9s 8ms/step - loss: 0.5154 - accuracy: 0.7370 - val_loss: 0.5157 - val_accuracy: 0.7347\n",
            "Epoch 7/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5143 - accuracy: 0.7374 - val_loss: 0.5130 - val_accuracy: 0.7377\n",
            "Epoch 8/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5130 - accuracy: 0.7381 - val_loss: 0.5112 - val_accuracy: 0.7368\n",
            "Epoch 9/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5121 - accuracy: 0.7380 - val_loss: 0.5110 - val_accuracy: 0.7375\n",
            "Epoch 10/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5115 - accuracy: 0.7389 - val_loss: 0.5085 - val_accuracy: 0.7385\n",
            "Epoch 11/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5100 - accuracy: 0.7400 - val_loss: 0.5085 - val_accuracy: 0.7379\n",
            "Epoch 12/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5095 - accuracy: 0.7404 - val_loss: 0.5143 - val_accuracy: 0.7374\n",
            "Epoch 13/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5083 - accuracy: 0.7413 - val_loss: 0.5106 - val_accuracy: 0.7388\n",
            "Epoch 14/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5084 - accuracy: 0.7401 - val_loss: 0.5078 - val_accuracy: 0.7387\n",
            "Epoch 15/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5072 - accuracy: 0.7416 - val_loss: 0.5089 - val_accuracy: 0.7395\n",
            "Epoch 16/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5072 - accuracy: 0.7415 - val_loss: 0.5073 - val_accuracy: 0.7399\n",
            "Epoch 17/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5063 - accuracy: 0.7425 - val_loss: 0.5080 - val_accuracy: 0.7399\n",
            "Epoch 18/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5054 - accuracy: 0.7425 - val_loss: 0.5074 - val_accuracy: 0.7398\n",
            "Epoch 19/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5047 - accuracy: 0.7432 - val_loss: 0.5054 - val_accuracy: 0.7410\n",
            "Epoch 20/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5039 - accuracy: 0.7435 - val_loss: 0.5055 - val_accuracy: 0.7413\n",
            "Epoch 21/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5039 - accuracy: 0.7435 - val_loss: 0.5069 - val_accuracy: 0.7418\n",
            "Epoch 22/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5035 - accuracy: 0.7443 - val_loss: 0.5077 - val_accuracy: 0.7403\n",
            "Epoch 23/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5029 - accuracy: 0.7438 - val_loss: 0.5077 - val_accuracy: 0.7377\n",
            "Epoch 24/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5023 - accuracy: 0.7448 - val_loss: 0.5074 - val_accuracy: 0.7388\n",
            "Epoch 25/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5020 - accuracy: 0.7448 - val_loss: 0.5059 - val_accuracy: 0.7398\n",
            "Epoch 26/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5014 - accuracy: 0.7457 - val_loss: 0.5049 - val_accuracy: 0.7419\n",
            "Epoch 27/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5012 - accuracy: 0.7458 - val_loss: 0.5051 - val_accuracy: 0.7410\n",
            "Epoch 28/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5006 - accuracy: 0.7448 - val_loss: 0.5064 - val_accuracy: 0.7401\n",
            "Epoch 29/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5000 - accuracy: 0.7463 - val_loss: 0.5061 - val_accuracy: 0.7394\n",
            "Epoch 30/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5001 - accuracy: 0.7465 - val_loss: 0.5043 - val_accuracy: 0.7424\n",
            "Epoch 31/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4993 - accuracy: 0.7459 - val_loss: 0.5056 - val_accuracy: 0.7420\n",
            "Epoch 32/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4982 - accuracy: 0.7472 - val_loss: 0.5064 - val_accuracy: 0.7431\n",
            "Epoch 33/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4987 - accuracy: 0.7468 - val_loss: 0.5053 - val_accuracy: 0.7385\n",
            "Epoch 34/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4984 - accuracy: 0.7469 - val_loss: 0.5034 - val_accuracy: 0.7416\n",
            "Epoch 35/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4975 - accuracy: 0.7475 - val_loss: 0.5031 - val_accuracy: 0.7441\n",
            "Epoch 36/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4974 - accuracy: 0.7480 - val_loss: 0.5029 - val_accuracy: 0.7427\n",
            "Epoch 37/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4968 - accuracy: 0.7483 - val_loss: 0.5051 - val_accuracy: 0.7438\n",
            "Epoch 38/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4968 - accuracy: 0.7487 - val_loss: 0.5022 - val_accuracy: 0.7431\n",
            "Epoch 39/1000\n",
            "1125/1125 [==============================] - 9s 8ms/step - loss: 0.4963 - accuracy: 0.7487 - val_loss: 0.5049 - val_accuracy: 0.7440\n",
            "Epoch 40/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4957 - accuracy: 0.7492 - val_loss: 0.5040 - val_accuracy: 0.7436\n",
            "Epoch 41/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4958 - accuracy: 0.7487 - val_loss: 0.5031 - val_accuracy: 0.7454\n",
            "Epoch 42/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4953 - accuracy: 0.7496 - val_loss: 0.5036 - val_accuracy: 0.7424\n",
            "Epoch 43/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4947 - accuracy: 0.7500 - val_loss: 0.5033 - val_accuracy: 0.7450\n",
            "Epoch 44/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4949 - accuracy: 0.7498 - val_loss: 0.5035 - val_accuracy: 0.7428\n",
            "Epoch 45/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4939 - accuracy: 0.7504 - val_loss: 0.5019 - val_accuracy: 0.7426\n",
            "Epoch 46/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4936 - accuracy: 0.7500 - val_loss: 0.5035 - val_accuracy: 0.7439\n",
            "Epoch 47/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4934 - accuracy: 0.7497 - val_loss: 0.5028 - val_accuracy: 0.7421\n",
            "Epoch 48/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4930 - accuracy: 0.7502 - val_loss: 0.5039 - val_accuracy: 0.7421\n",
            "Epoch 49/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4924 - accuracy: 0.7510 - val_loss: 0.5033 - val_accuracy: 0.7433\n",
            "Epoch 50/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4929 - accuracy: 0.7513 - val_loss: 0.5030 - val_accuracy: 0.7433\n",
            "Epoch 51/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4924 - accuracy: 0.7507 - val_loss: 0.5034 - val_accuracy: 0.7422\n",
            "Epoch 52/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4920 - accuracy: 0.7519 - val_loss: 0.5045 - val_accuracy: 0.7439\n",
            "Epoch 53/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4922 - accuracy: 0.7517 - val_loss: 0.5013 - val_accuracy: 0.7453\n",
            "Epoch 54/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4918 - accuracy: 0.7519 - val_loss: 0.5012 - val_accuracy: 0.7432\n",
            "Epoch 55/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4914 - accuracy: 0.7511 - val_loss: 0.5016 - val_accuracy: 0.7428\n",
            "Epoch 56/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4904 - accuracy: 0.7522 - val_loss: 0.5019 - val_accuracy: 0.7440\n",
            "Epoch 57/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4903 - accuracy: 0.7527 - val_loss: 0.5024 - val_accuracy: 0.7458\n",
            "Epoch 58/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4898 - accuracy: 0.7528 - val_loss: 0.5020 - val_accuracy: 0.7463\n",
            "Epoch 59/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4896 - accuracy: 0.7529 - val_loss: 0.5027 - val_accuracy: 0.7423\n",
            "Epoch 60/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4901 - accuracy: 0.7529 - val_loss: 0.5048 - val_accuracy: 0.7441\n",
            "Epoch 61/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4888 - accuracy: 0.7535 - val_loss: 0.5063 - val_accuracy: 0.7433\n",
            "Epoch 62/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4892 - accuracy: 0.7527 - val_loss: 0.5027 - val_accuracy: 0.7434\n",
            "Epoch 63/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4888 - accuracy: 0.7532 - val_loss: 0.5040 - val_accuracy: 0.7433\n",
            "Epoch 64/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4887 - accuracy: 0.7536 - val_loss: 0.5048 - val_accuracy: 0.7438\n",
            "7028/7028 [==============================] - 10s 1ms/step\n",
            "781/781 [==============================] - 1s 1ms/step\n",
            "Epoch 1/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5385 - accuracy: 0.7243 - val_loss: 0.5247 - val_accuracy: 0.7327\n",
            "Epoch 2/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5254 - accuracy: 0.7315 - val_loss: 0.5230 - val_accuracy: 0.7271\n",
            "Epoch 3/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5215 - accuracy: 0.7333 - val_loss: 0.5177 - val_accuracy: 0.7378\n",
            "Epoch 4/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5185 - accuracy: 0.7342 - val_loss: 0.5159 - val_accuracy: 0.7347\n",
            "Epoch 5/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5168 - accuracy: 0.7359 - val_loss: 0.5133 - val_accuracy: 0.7379\n",
            "Epoch 6/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5153 - accuracy: 0.7367 - val_loss: 0.5134 - val_accuracy: 0.7390\n",
            "Epoch 7/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5143 - accuracy: 0.7368 - val_loss: 0.5129 - val_accuracy: 0.7390\n",
            "Epoch 8/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5129 - accuracy: 0.7371 - val_loss: 0.5083 - val_accuracy: 0.7407\n",
            "Epoch 9/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5116 - accuracy: 0.7394 - val_loss: 0.5084 - val_accuracy: 0.7416\n",
            "Epoch 10/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5110 - accuracy: 0.7401 - val_loss: 0.5076 - val_accuracy: 0.7432\n",
            "Epoch 11/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5102 - accuracy: 0.7393 - val_loss: 0.5082 - val_accuracy: 0.7410\n",
            "Epoch 12/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5094 - accuracy: 0.7402 - val_loss: 0.5090 - val_accuracy: 0.7427\n",
            "Epoch 13/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5085 - accuracy: 0.7407 - val_loss: 0.5120 - val_accuracy: 0.7402\n",
            "Epoch 14/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5074 - accuracy: 0.7416 - val_loss: 0.5074 - val_accuracy: 0.7416\n",
            "Epoch 15/1000\n",
            "1125/1125 [==============================] - 8s 8ms/step - loss: 0.5064 - accuracy: 0.7423 - val_loss: 0.5061 - val_accuracy: 0.7406\n",
            "Epoch 16/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5061 - accuracy: 0.7414 - val_loss: 0.5075 - val_accuracy: 0.7408\n",
            "Epoch 17/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5052 - accuracy: 0.7425 - val_loss: 0.5062 - val_accuracy: 0.7433\n",
            "Epoch 18/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5049 - accuracy: 0.7431 - val_loss: 0.5083 - val_accuracy: 0.7394\n",
            "Epoch 19/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5039 - accuracy: 0.7425 - val_loss: 0.5057 - val_accuracy: 0.7416\n",
            "Epoch 20/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5037 - accuracy: 0.7439 - val_loss: 0.5057 - val_accuracy: 0.7446\n",
            "Epoch 21/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5032 - accuracy: 0.7440 - val_loss: 0.5049 - val_accuracy: 0.7428\n",
            "Epoch 22/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5028 - accuracy: 0.7445 - val_loss: 0.5057 - val_accuracy: 0.7420\n",
            "Epoch 23/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5023 - accuracy: 0.7450 - val_loss: 0.5045 - val_accuracy: 0.7431\n",
            "Epoch 24/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5017 - accuracy: 0.7446 - val_loss: 0.5043 - val_accuracy: 0.7437\n",
            "Epoch 25/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5006 - accuracy: 0.7451 - val_loss: 0.5049 - val_accuracy: 0.7440\n",
            "Epoch 26/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5011 - accuracy: 0.7449 - val_loss: 0.5040 - val_accuracy: 0.7443\n",
            "Epoch 27/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5005 - accuracy: 0.7455 - val_loss: 0.5058 - val_accuracy: 0.7434\n",
            "Epoch 28/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5003 - accuracy: 0.7460 - val_loss: 0.5040 - val_accuracy: 0.7447\n",
            "Epoch 29/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4995 - accuracy: 0.7459 - val_loss: 0.5050 - val_accuracy: 0.7460\n",
            "Epoch 30/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4989 - accuracy: 0.7469 - val_loss: 0.5049 - val_accuracy: 0.7441\n",
            "Epoch 31/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4987 - accuracy: 0.7466 - val_loss: 0.5039 - val_accuracy: 0.7461\n",
            "Epoch 32/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4982 - accuracy: 0.7465 - val_loss: 0.5030 - val_accuracy: 0.7447\n",
            "Epoch 33/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4977 - accuracy: 0.7476 - val_loss: 0.5030 - val_accuracy: 0.7451\n",
            "Epoch 34/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4973 - accuracy: 0.7479 - val_loss: 0.5056 - val_accuracy: 0.7423\n",
            "Epoch 35/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4966 - accuracy: 0.7477 - val_loss: 0.5037 - val_accuracy: 0.7454\n",
            "Epoch 36/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4959 - accuracy: 0.7483 - val_loss: 0.5054 - val_accuracy: 0.7428\n",
            "Epoch 37/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4963 - accuracy: 0.7477 - val_loss: 0.5040 - val_accuracy: 0.7459\n",
            "Epoch 38/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4956 - accuracy: 0.7479 - val_loss: 0.5051 - val_accuracy: 0.7453\n",
            "Epoch 39/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4954 - accuracy: 0.7487 - val_loss: 0.5060 - val_accuracy: 0.7436\n",
            "Epoch 40/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4948 - accuracy: 0.7489 - val_loss: 0.5046 - val_accuracy: 0.7418\n",
            "Epoch 41/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4948 - accuracy: 0.7491 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
            "Epoch 42/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4947 - accuracy: 0.7491 - val_loss: 0.5072 - val_accuracy: 0.7440\n",
            "7028/7028 [==============================] - 11s 2ms/step\n",
            "781/781 [==============================] - 1s 1ms/step\n",
            "Epoch 1/1000\n",
            "1125/1125 [==============================] - 8s 6ms/step - loss: 0.5385 - accuracy: 0.7243 - val_loss: 0.5250 - val_accuracy: 0.7312\n",
            "Epoch 2/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5256 - accuracy: 0.7316 - val_loss: 0.5196 - val_accuracy: 0.7321\n",
            "Epoch 3/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5216 - accuracy: 0.7336 - val_loss: 0.5177 - val_accuracy: 0.7304\n",
            "Epoch 4/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5184 - accuracy: 0.7352 - val_loss: 0.5154 - val_accuracy: 0.7344\n",
            "Epoch 5/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5170 - accuracy: 0.7357 - val_loss: 0.5144 - val_accuracy: 0.7353\n",
            "Epoch 6/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5153 - accuracy: 0.7376 - val_loss: 0.5153 - val_accuracy: 0.7362\n",
            "Epoch 7/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5145 - accuracy: 0.7377 - val_loss: 0.5139 - val_accuracy: 0.7352\n",
            "Epoch 8/1000\n",
            "1125/1125 [==============================] - 9s 8ms/step - loss: 0.5126 - accuracy: 0.7385 - val_loss: 0.5138 - val_accuracy: 0.7359\n",
            "Epoch 9/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5120 - accuracy: 0.7384 - val_loss: 0.5208 - val_accuracy: 0.7351\n",
            "Epoch 10/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5108 - accuracy: 0.7392 - val_loss: 0.5134 - val_accuracy: 0.7353\n",
            "Epoch 11/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5100 - accuracy: 0.7405 - val_loss: 0.5117 - val_accuracy: 0.7376\n",
            "Epoch 12/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5091 - accuracy: 0.7405 - val_loss: 0.5105 - val_accuracy: 0.7387\n",
            "Epoch 13/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5082 - accuracy: 0.7411 - val_loss: 0.5094 - val_accuracy: 0.7381\n",
            "Epoch 14/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5070 - accuracy: 0.7415 - val_loss: 0.5112 - val_accuracy: 0.7376\n",
            "Epoch 15/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5068 - accuracy: 0.7413 - val_loss: 0.5089 - val_accuracy: 0.7374\n",
            "Epoch 16/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5055 - accuracy: 0.7426 - val_loss: 0.5087 - val_accuracy: 0.7369\n",
            "Epoch 17/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5053 - accuracy: 0.7425 - val_loss: 0.5091 - val_accuracy: 0.7407\n",
            "Epoch 18/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5047 - accuracy: 0.7428 - val_loss: 0.5108 - val_accuracy: 0.7374\n",
            "Epoch 19/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5043 - accuracy: 0.7432 - val_loss: 0.5075 - val_accuracy: 0.7392\n",
            "Epoch 20/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5036 - accuracy: 0.7431 - val_loss: 0.5091 - val_accuracy: 0.7387\n",
            "Epoch 21/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5030 - accuracy: 0.7444 - val_loss: 0.5075 - val_accuracy: 0.7398\n",
            "Epoch 22/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5026 - accuracy: 0.7447 - val_loss: 0.5074 - val_accuracy: 0.7390\n",
            "Epoch 23/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5022 - accuracy: 0.7445 - val_loss: 0.5084 - val_accuracy: 0.7393\n",
            "Epoch 24/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5011 - accuracy: 0.7456 - val_loss: 0.5072 - val_accuracy: 0.7396\n",
            "Epoch 25/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5012 - accuracy: 0.7449 - val_loss: 0.5090 - val_accuracy: 0.7392\n",
            "Epoch 26/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5005 - accuracy: 0.7456 - val_loss: 0.5096 - val_accuracy: 0.7389\n",
            "Epoch 27/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5001 - accuracy: 0.7459 - val_loss: 0.5071 - val_accuracy: 0.7395\n",
            "Epoch 28/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4994 - accuracy: 0.7475 - val_loss: 0.5066 - val_accuracy: 0.7403\n",
            "Epoch 29/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4992 - accuracy: 0.7470 - val_loss: 0.5070 - val_accuracy: 0.7416\n",
            "Epoch 30/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4982 - accuracy: 0.7476 - val_loss: 0.5082 - val_accuracy: 0.7399\n",
            "Epoch 31/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4978 - accuracy: 0.7466 - val_loss: 0.5050 - val_accuracy: 0.7401\n",
            "Epoch 32/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4975 - accuracy: 0.7482 - val_loss: 0.5077 - val_accuracy: 0.7402\n",
            "Epoch 33/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4971 - accuracy: 0.7484 - val_loss: 0.5078 - val_accuracy: 0.7418\n",
            "Epoch 34/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4969 - accuracy: 0.7481 - val_loss: 0.5052 - val_accuracy: 0.7408\n",
            "Epoch 35/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4968 - accuracy: 0.7492 - val_loss: 0.5060 - val_accuracy: 0.7406\n",
            "Epoch 36/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4961 - accuracy: 0.7482 - val_loss: 0.5067 - val_accuracy: 0.7404\n",
            "Epoch 37/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4959 - accuracy: 0.7492 - val_loss: 0.5076 - val_accuracy: 0.7403\n",
            "Epoch 38/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4954 - accuracy: 0.7491 - val_loss: 0.5059 - val_accuracy: 0.7387\n",
            "Epoch 39/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4945 - accuracy: 0.7497 - val_loss: 0.5064 - val_accuracy: 0.7426\n",
            "Epoch 40/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4943 - accuracy: 0.7494 - val_loss: 0.5065 - val_accuracy: 0.7404\n",
            "Epoch 41/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4942 - accuracy: 0.7495 - val_loss: 0.5050 - val_accuracy: 0.7418\n",
            "7028/7028 [==============================] - 11s 2ms/step\n",
            "781/781 [==============================] - 1s 1ms/step\n",
            "Epoch 1/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5383 - accuracy: 0.7236 - val_loss: 0.5224 - val_accuracy: 0.7334\n",
            "Epoch 2/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5252 - accuracy: 0.7320 - val_loss: 0.5175 - val_accuracy: 0.7349\n",
            "Epoch 3/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5216 - accuracy: 0.7332 - val_loss: 0.5140 - val_accuracy: 0.7359\n",
            "Epoch 4/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5189 - accuracy: 0.7349 - val_loss: 0.5179 - val_accuracy: 0.7381\n",
            "Epoch 5/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5169 - accuracy: 0.7364 - val_loss: 0.5152 - val_accuracy: 0.7376\n",
            "Epoch 6/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5158 - accuracy: 0.7363 - val_loss: 0.5115 - val_accuracy: 0.7390\n",
            "Epoch 7/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5145 - accuracy: 0.7367 - val_loss: 0.5129 - val_accuracy: 0.7371\n",
            "Epoch 8/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5139 - accuracy: 0.7374 - val_loss: 0.5095 - val_accuracy: 0.7411\n",
            "Epoch 9/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5126 - accuracy: 0.7379 - val_loss: 0.5090 - val_accuracy: 0.7414\n",
            "Epoch 10/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5115 - accuracy: 0.7397 - val_loss: 0.5078 - val_accuracy: 0.7394\n",
            "Epoch 11/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.5103 - accuracy: 0.7397 - val_loss: 0.5090 - val_accuracy: 0.7395\n",
            "Epoch 12/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5096 - accuracy: 0.7398 - val_loss: 0.5085 - val_accuracy: 0.7412\n",
            "Epoch 13/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5088 - accuracy: 0.7410 - val_loss: 0.5078 - val_accuracy: 0.7406\n",
            "Epoch 14/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.5079 - accuracy: 0.7414 - val_loss: 0.5067 - val_accuracy: 0.7397\n",
            "Epoch 15/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5076 - accuracy: 0.7412 - val_loss: 0.5078 - val_accuracy: 0.7392\n",
            "Epoch 16/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5074 - accuracy: 0.7405 - val_loss: 0.5085 - val_accuracy: 0.7416\n",
            "Epoch 17/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5067 - accuracy: 0.7423 - val_loss: 0.5070 - val_accuracy: 0.7428\n",
            "Epoch 18/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5060 - accuracy: 0.7426 - val_loss: 0.5048 - val_accuracy: 0.7440\n",
            "Epoch 19/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5054 - accuracy: 0.7427 - val_loss: 0.5054 - val_accuracy: 0.7446\n",
            "Epoch 20/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5047 - accuracy: 0.7436 - val_loss: 0.5060 - val_accuracy: 0.7430\n",
            "Epoch 21/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5042 - accuracy: 0.7432 - val_loss: 0.5074 - val_accuracy: 0.7421\n",
            "Epoch 22/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5037 - accuracy: 0.7442 - val_loss: 0.5057 - val_accuracy: 0.7433\n",
            "Epoch 23/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5036 - accuracy: 0.7444 - val_loss: 0.5052 - val_accuracy: 0.7433\n",
            "Epoch 24/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5024 - accuracy: 0.7439 - val_loss: 0.5058 - val_accuracy: 0.7439\n",
            "Epoch 25/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5027 - accuracy: 0.7444 - val_loss: 0.5040 - val_accuracy: 0.7447\n",
            "Epoch 26/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5017 - accuracy: 0.7443 - val_loss: 0.5045 - val_accuracy: 0.7414\n",
            "Epoch 27/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5014 - accuracy: 0.7453 - val_loss: 0.5049 - val_accuracy: 0.7433\n",
            "Epoch 28/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5007 - accuracy: 0.7451 - val_loss: 0.5037 - val_accuracy: 0.7430\n",
            "Epoch 29/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5002 - accuracy: 0.7469 - val_loss: 0.5039 - val_accuracy: 0.7452\n",
            "Epoch 30/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5000 - accuracy: 0.7465 - val_loss: 0.5048 - val_accuracy: 0.7429\n",
            "Epoch 31/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4991 - accuracy: 0.7466 - val_loss: 0.5041 - val_accuracy: 0.7428\n",
            "Epoch 32/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4992 - accuracy: 0.7463 - val_loss: 0.5066 - val_accuracy: 0.7417\n",
            "Epoch 33/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4990 - accuracy: 0.7461 - val_loss: 0.5041 - val_accuracy: 0.7430\n",
            "Epoch 34/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4988 - accuracy: 0.7468 - val_loss: 0.5023 - val_accuracy: 0.7442\n",
            "Epoch 35/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4980 - accuracy: 0.7477 - val_loss: 0.5035 - val_accuracy: 0.7438\n",
            "Epoch 36/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4975 - accuracy: 0.7477 - val_loss: 0.5045 - val_accuracy: 0.7453\n",
            "Epoch 37/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4971 - accuracy: 0.7475 - val_loss: 0.5063 - val_accuracy: 0.7433\n",
            "Epoch 38/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4966 - accuracy: 0.7480 - val_loss: 0.5042 - val_accuracy: 0.7428\n",
            "Epoch 39/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4962 - accuracy: 0.7478 - val_loss: 0.5048 - val_accuracy: 0.7453\n",
            "Epoch 40/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4957 - accuracy: 0.7494 - val_loss: 0.5031 - val_accuracy: 0.7440\n",
            "Epoch 41/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4963 - accuracy: 0.7478 - val_loss: 0.5026 - val_accuracy: 0.7434\n",
            "Epoch 42/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4956 - accuracy: 0.7490 - val_loss: 0.5036 - val_accuracy: 0.7443\n",
            "Epoch 43/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4946 - accuracy: 0.7499 - val_loss: 0.5038 - val_accuracy: 0.7442\n",
            "Epoch 44/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4948 - accuracy: 0.7490 - val_loss: 0.5018 - val_accuracy: 0.7438\n",
            "Epoch 45/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4941 - accuracy: 0.7507 - val_loss: 0.5027 - val_accuracy: 0.7451\n",
            "Epoch 46/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4942 - accuracy: 0.7486 - val_loss: 0.5035 - val_accuracy: 0.7441\n",
            "Epoch 47/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4942 - accuracy: 0.7494 - val_loss: 0.5025 - val_accuracy: 0.7444\n",
            "Epoch 48/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4933 - accuracy: 0.7504 - val_loss: 0.5021 - val_accuracy: 0.7462\n",
            "Epoch 49/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4932 - accuracy: 0.7504 - val_loss: 0.5025 - val_accuracy: 0.7463\n",
            "Epoch 50/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4926 - accuracy: 0.7514 - val_loss: 0.5032 - val_accuracy: 0.7462\n",
            "Epoch 51/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4928 - accuracy: 0.7502 - val_loss: 0.5026 - val_accuracy: 0.7450\n",
            "Epoch 52/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4926 - accuracy: 0.7514 - val_loss: 0.5013 - val_accuracy: 0.7456\n",
            "Epoch 53/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4914 - accuracy: 0.7511 - val_loss: 0.5019 - val_accuracy: 0.7448\n",
            "Epoch 54/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4915 - accuracy: 0.7519 - val_loss: 0.5032 - val_accuracy: 0.7458\n",
            "Epoch 55/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4913 - accuracy: 0.7516 - val_loss: 0.5020 - val_accuracy: 0.7460\n",
            "Epoch 56/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4906 - accuracy: 0.7522 - val_loss: 0.5023 - val_accuracy: 0.7434\n",
            "Epoch 57/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4911 - accuracy: 0.7518 - val_loss: 0.5020 - val_accuracy: 0.7422\n",
            "Epoch 58/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4907 - accuracy: 0.7521 - val_loss: 0.5026 - val_accuracy: 0.7449\n",
            "Epoch 59/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4898 - accuracy: 0.7528 - val_loss: 0.5026 - val_accuracy: 0.7457\n",
            "Epoch 60/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4896 - accuracy: 0.7532 - val_loss: 0.5030 - val_accuracy: 0.7471\n",
            "Epoch 61/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4895 - accuracy: 0.7527 - val_loss: 0.5025 - val_accuracy: 0.7471\n",
            "Epoch 62/1000\n",
            "1125/1125 [==============================] - 8s 8ms/step - loss: 0.4898 - accuracy: 0.7534 - val_loss: 0.5030 - val_accuracy: 0.7459\n",
            "7028/7028 [==============================] - 13s 2ms/step\n",
            "781/781 [==============================] - 1s 2ms/step\n",
            "Epoch 1/1000\n",
            "1125/1125 [==============================] - 10s 8ms/step - loss: 0.5393 - accuracy: 0.7240 - val_loss: 0.5232 - val_accuracy: 0.7348\n",
            "Epoch 2/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5253 - accuracy: 0.7315 - val_loss: 0.5250 - val_accuracy: 0.7336\n",
            "Epoch 3/1000\n",
            "1125/1125 [==============================] - 9s 8ms/step - loss: 0.5218 - accuracy: 0.7336 - val_loss: 0.5150 - val_accuracy: 0.7358\n",
            "Epoch 4/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5189 - accuracy: 0.7344 - val_loss: 0.5137 - val_accuracy: 0.7399\n",
            "Epoch 5/1000\n",
            "1125/1125 [==============================] - 9s 8ms/step - loss: 0.5172 - accuracy: 0.7353 - val_loss: 0.5125 - val_accuracy: 0.7391\n",
            "Epoch 6/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5151 - accuracy: 0.7372 - val_loss: 0.5113 - val_accuracy: 0.7371\n",
            "Epoch 7/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5142 - accuracy: 0.7368 - val_loss: 0.5104 - val_accuracy: 0.7400\n",
            "Epoch 8/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5133 - accuracy: 0.7385 - val_loss: 0.5112 - val_accuracy: 0.7402\n",
            "Epoch 9/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5116 - accuracy: 0.7386 - val_loss: 0.5112 - val_accuracy: 0.7382\n",
            "Epoch 10/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5114 - accuracy: 0.7389 - val_loss: 0.5085 - val_accuracy: 0.7410\n",
            "Epoch 11/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5103 - accuracy: 0.7392 - val_loss: 0.5092 - val_accuracy: 0.7410\n",
            "Epoch 12/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5094 - accuracy: 0.7404 - val_loss: 0.5101 - val_accuracy: 0.7416\n",
            "Epoch 13/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5084 - accuracy: 0.7402 - val_loss: 0.5109 - val_accuracy: 0.7417\n",
            "Epoch 14/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5084 - accuracy: 0.7404 - val_loss: 0.5106 - val_accuracy: 0.7421\n",
            "Epoch 15/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5070 - accuracy: 0.7423 - val_loss: 0.5081 - val_accuracy: 0.7438\n",
            "Epoch 16/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5066 - accuracy: 0.7421 - val_loss: 0.5085 - val_accuracy: 0.7405\n",
            "Epoch 17/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5062 - accuracy: 0.7414 - val_loss: 0.5067 - val_accuracy: 0.7432\n",
            "Epoch 18/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5049 - accuracy: 0.7426 - val_loss: 0.5062 - val_accuracy: 0.7434\n",
            "Epoch 19/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5052 - accuracy: 0.7429 - val_loss: 0.5072 - val_accuracy: 0.7443\n",
            "Epoch 20/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5043 - accuracy: 0.7430 - val_loss: 0.5051 - val_accuracy: 0.7429\n",
            "Epoch 21/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5038 - accuracy: 0.7433 - val_loss: 0.5062 - val_accuracy: 0.7413\n",
            "Epoch 22/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5028 - accuracy: 0.7440 - val_loss: 0.5049 - val_accuracy: 0.7440\n",
            "Epoch 23/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5026 - accuracy: 0.7437 - val_loss: 0.5067 - val_accuracy: 0.7427\n",
            "Epoch 24/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5018 - accuracy: 0.7446 - val_loss: 0.5040 - val_accuracy: 0.7444\n",
            "Epoch 25/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5018 - accuracy: 0.7448 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
            "Epoch 26/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5008 - accuracy: 0.7450 - val_loss: 0.5087 - val_accuracy: 0.7445\n",
            "Epoch 27/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5004 - accuracy: 0.7458 - val_loss: 0.5041 - val_accuracy: 0.7451\n",
            "Epoch 28/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.5002 - accuracy: 0.7463 - val_loss: 0.5061 - val_accuracy: 0.7428\n",
            "Epoch 29/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4995 - accuracy: 0.7459 - val_loss: 0.5054 - val_accuracy: 0.7450\n",
            "Epoch 30/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4994 - accuracy: 0.7463 - val_loss: 0.5054 - val_accuracy: 0.7422\n",
            "Epoch 31/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4989 - accuracy: 0.7475 - val_loss: 0.5054 - val_accuracy: 0.7436\n",
            "Epoch 32/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4989 - accuracy: 0.7462 - val_loss: 0.5040 - val_accuracy: 0.7459\n",
            "Epoch 33/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4982 - accuracy: 0.7480 - val_loss: 0.5058 - val_accuracy: 0.7426\n",
            "Epoch 34/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4977 - accuracy: 0.7477 - val_loss: 0.5038 - val_accuracy: 0.7443\n",
            "Epoch 35/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4978 - accuracy: 0.7480 - val_loss: 0.5038 - val_accuracy: 0.7443\n",
            "Epoch 36/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4972 - accuracy: 0.7481 - val_loss: 0.5044 - val_accuracy: 0.7457\n",
            "Epoch 37/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4965 - accuracy: 0.7478 - val_loss: 0.5050 - val_accuracy: 0.7439\n",
            "Epoch 38/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4964 - accuracy: 0.7474 - val_loss: 0.5037 - val_accuracy: 0.7456\n",
            "Epoch 39/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4956 - accuracy: 0.7485 - val_loss: 0.5063 - val_accuracy: 0.7442\n",
            "Epoch 40/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4957 - accuracy: 0.7479 - val_loss: 0.5025 - val_accuracy: 0.7460\n",
            "Epoch 41/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4950 - accuracy: 0.7488 - val_loss: 0.5044 - val_accuracy: 0.7446\n",
            "Epoch 42/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4952 - accuracy: 0.7496 - val_loss: 0.5032 - val_accuracy: 0.7429\n",
            "Epoch 43/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4941 - accuracy: 0.7495 - val_loss: 0.5052 - val_accuracy: 0.7446\n",
            "Epoch 44/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4945 - accuracy: 0.7496 - val_loss: 0.5052 - val_accuracy: 0.7438\n",
            "Epoch 45/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4931 - accuracy: 0.7502 - val_loss: 0.5050 - val_accuracy: 0.7459\n",
            "Epoch 46/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4929 - accuracy: 0.7505 - val_loss: 0.5031 - val_accuracy: 0.7446\n",
            "Epoch 47/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4926 - accuracy: 0.7509 - val_loss: 0.5050 - val_accuracy: 0.7466\n",
            "Epoch 48/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4924 - accuracy: 0.7498 - val_loss: 0.5025 - val_accuracy: 0.7480\n",
            "Epoch 49/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4922 - accuracy: 0.7507 - val_loss: 0.5027 - val_accuracy: 0.7475\n",
            "Epoch 50/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4913 - accuracy: 0.7514 - val_loss: 0.5013 - val_accuracy: 0.7480\n",
            "Epoch 51/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4913 - accuracy: 0.7517 - val_loss: 0.5025 - val_accuracy: 0.7443\n",
            "Epoch 52/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4913 - accuracy: 0.7523 - val_loss: 0.5022 - val_accuracy: 0.7466\n",
            "Epoch 53/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4909 - accuracy: 0.7517 - val_loss: 0.5028 - val_accuracy: 0.7469\n",
            "Epoch 54/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4905 - accuracy: 0.7518 - val_loss: 0.5043 - val_accuracy: 0.7457\n",
            "Epoch 55/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4909 - accuracy: 0.7522 - val_loss: 0.5036 - val_accuracy: 0.7478\n",
            "Epoch 56/1000\n",
            "1125/1125 [==============================] - 7s 6ms/step - loss: 0.4899 - accuracy: 0.7519 - val_loss: 0.5022 - val_accuracy: 0.7456\n",
            "Epoch 57/1000\n",
            "1125/1125 [==============================] - 7s 7ms/step - loss: 0.4901 - accuracy: 0.7525 - val_loss: 0.5041 - val_accuracy: 0.7459\n",
            "Epoch 58/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4896 - accuracy: 0.7521 - val_loss: 0.5037 - val_accuracy: 0.7473\n",
            "Epoch 59/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4894 - accuracy: 0.7536 - val_loss: 0.5046 - val_accuracy: 0.7455\n",
            "Epoch 60/1000\n",
            "1125/1125 [==============================] - 8s 7ms/step - loss: 0.4893 - accuracy: 0.7530 - val_loss: 0.5026 - val_accuracy: 0.7472\n",
            "7028/7028 [==============================] - 11s 2ms/step\n",
            "781/781 [==============================] - 1s 1ms/step\n",
            "Entrenamiento - Accuracy: 75.58%\n",
            "Entrenamiento - Precision: 74.05%\n",
            "Entrenamiento - Recall: 78.76%\n",
            "Entrenamiento - F1 Score: 76.33%\n",
            "Validación - Accuracy: 74.46%\n",
            "Validación - Precision: 73.00%\n",
            "Validación - Recall: 77.67%\n",
            "Validación - F1 Score: 75.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guardar el modelo\n"
      ],
      "metadata": {
        "id": "hswZRn1z3d8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import os\n",
        "# Directorio para guardar modelos entrenados\n",
        "model_dir = '/content/drive/MyDrive/Experimentación Python Tesis /Modelos ya entrenados'\n",
        "model_filename = 'TWEETS_depresivos (RN-Word2Vec).pkl'\n",
        "model_path_p = os.path.join(model_dir, model_filename)\n",
        "\n",
        "# Guardar el modelo entrenado\n",
        "joblib.dump(model, model_path_p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQdVv-G03iEA",
        "outputId": "28b505b0-4f74-4144-8abf-aaad945f5c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Experimentación Python Tesis /Modelos ya entrenados/TWEETS_depresivos (RN-Word2Vec).pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluación"
      ],
      "metadata": {
        "id": "OKVFul8f6uKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Función para calcular el vector promedio de un documento\n",
        "def document_vector(tokens, modeWl):\n",
        "    # Filtrar palabras que no están en el modelo Word2Vec\n",
        "    tokens = [token for token in tokens if token in modelW.wv.key_to_index]\n",
        "    if len(tokens) == 0:\n",
        "        return np.zeros(modelW.vector_size)\n",
        "    return np.mean([modelW.wv[token] for token in tokens], axis=0)\n",
        "\n",
        "# Aplicar transformaciones al conjunto de pruebas\n",
        "data_test['TWEET_TEXT'] = data_test['TWEET_TEXT'].apply(removeHTML)\n",
        "data_test['TWEET_TEXT'] = data_test['TWEET_TEXT'].apply(clean)\n",
        "data_test['TWEET_TEXT'] = data_test['TWEET_TEXT'].apply(extractTerms)\n",
        "\n",
        "# Obtener representaciones Word2Vec para el conjunto de pruebas\n",
        "X_test_word2vec = [document_vector(tokens, modelW) for tokens in data_test['TWEET_TEXT']]\n",
        "\n",
        "# Crear el conjunto de pruebas\n",
        "X_test = np.array(X_test_word2vec)\n",
        "y_test = data_test['trastorno'].values\n",
        "\n",
        "# Predicciones en el conjunto de pruebas\n",
        "y_test_pred = (model.predict(X_test) > 0.5).astype(int)  # Aquí asumimos un umbral de 0.5 para la clasificación\n",
        "\n",
        "# Calcular precisión en el conjunto de pruebas\n",
        "precision_test = precision_score(y_test, y_test_pred)\n",
        "\n",
        "# Calcular exhaustividad (recall) en el conjunto de pruebas\n",
        "recall_test = recall_score(y_test, y_test_pred)\n",
        "\n",
        "# Calcular puntuación F1 en el conjunto de pruebas\n",
        "f1_test = f1_score(y_test, y_test_pred)\n",
        "\n",
        "# Calcular exactitud en el conjunto de pruebas (opcional)\n",
        "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "# Imprimir métricas de evaluación con el símbolo '%'\n",
        "print(\"Precisión: {:.2f}%\".format(precision_test * 100))\n",
        "print(\"Exhaustividad (Recall): {:.2f}%\".format(recall_test * 100))\n",
        "print(\"Puntuación F1: {:.2f}%\".format(f1_test * 100))\n",
        "print(\"Exactitud: {:.2f}%\".format(accuracy_test * 100))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b69DHqTn6zF0",
        "outputId": "fdf77fa8-8511-45c2-a2fc-8a75a5840328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 0s 2ms/step\n",
            "Precisión: 72.55%\n",
            "Exhaustividad (Recall): 71.30%\n",
            "Puntuación F1: 71.92%\n",
            "Exactitud: 72.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MATRIZ DE CONFUSIÓN"
      ],
      "metadata": {
        "id": "AWyCEaEuAzmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Obtiene la matriz de confusión. Las filas corresponden a las clases reales,\n",
        "umbral = 0.5  # Puedes ajustar este umbral según tus necesidades\n",
        "y_pred_binario = (y_pred > umbral).astype(int)\n",
        "\n",
        "# Calcular la matriz de confusión con las etiquetas binarias\n",
        "cm = confusion_matrix(y_test, y_pred_binario)\n",
        "prop_real = np.sum(y_test)/len(y_test)\n",
        "prop_etiqutados = (cm[0,1]+cm[1,1])/len(y_test)\n",
        "\n",
        "print(\"Matriz de confusión: \\n\\n\", cm, \"\\n\")\n",
        "print('Proporción de comentarios positivos: %.2f'% prop_real)\n",
        "print('Proporción de comentarios positivos etiquetados: %.2f'% prop_etiqutados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9q5A52IA4N-",
        "outputId": "d21515ec-6ae8-4295-8135-01fc976477c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 0s 2ms/step\n",
            "Matriz de confusión: \n",
            "\n",
            " [[1828  674]\n",
            " [ 717 1781]] \n",
            "\n",
            "Proporción de comentarios positivos: 0.50\n",
            "Proporción de comentarios positivos etiquetados: 0.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Crear una figura para la matriz de confusión\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Crear una matriz de confusión usando el heatmap de Seaborn\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['0', '1'], yticklabels=['0', '1'])\n",
        "\n",
        "# Etiquetas y título\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusión')\n",
        "\n",
        "# Mostrar la gráfica\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "V8dbR_W2BBAp",
        "outputId": "7cd85280-9e14-4561-8565-e27353d719dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 671,
              "height": 553
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo Entrenado"
      ],
      "metadata": {
        "id": "fmCfziQbBHqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Cargar el modelo entrenado\n",
        "model_path = '/content/drive/MyDrive/Experimentación Python Tesis /Modelos ya entrenados/TWEETS_depresivos (RN-Word2Vec).pkl'\n",
        "loaded_model = joblib.load(model_path)\n",
        "\n",
        "# Texto de ejemplo para predecir\n",
        "new_tweet = \"Que feo cuando te dicen un comentario y vos sabes que te duele cuando sentis ese nudo en la garganta y esas ganas de llorar\"\n",
        "\n",
        "# Preprocesamiento del texto\n",
        "new_tweet_cleaned = clean(removeHTML(new_tweet))\n",
        "new_tweet_extracted = extractTerms(new_tweet_cleaned)\n",
        "new_tweet_combined = ' '.join(new_tweet_extracted)\n",
        "\n",
        "# modelW = Word2Vec(data_train['TWEET_TEXT'], vector_size=100, window=5, min_count=1, sg=0)\n",
        "def document_vector(tokens, modelW):\n",
        "    # Filtrar palabras que no están en el modelo\n",
        "    tokens = [token for token in tokens if token in modelW.wv.key_to_index]\n",
        "    if len(tokens) == 0:\n",
        "        return np.zeros(modelW.vector_size)\n",
        "    return np.mean([modelW.wv[token] for token in tokens], axis=0)\n",
        "\n",
        "# Supongamos que 'word2vec_model' es tu modelo Word2Vec entrenado previamente\n",
        "new_tweet_word2vec = document_vector(new_tweet_extracted, modelW)\n",
        "\n",
        "# Redimensionar new_tweet_word2vec a una matriz 2D\n",
        "new_tweet_word2vec = np.array([new_tweet_word2vec])\n",
        "\n",
        "# Hacer la predicción y obtener las probabilidades de predicción\n",
        "proba_prediction = loaded_model.predict(new_tweet_word2vec)\n",
        "\n",
        "# Verificar la forma de proba_prediction\n",
        "if proba_prediction.shape[1] == 1:\n",
        "    # Solo una probabilidad en proba_prediction, se asume que es la probabilidad de clase 1\n",
        "    control_prob = 1 - proba_prediction[0][0]  # Probabilidad de ser control\n",
        "    depresion_prob = proba_prediction[0][0]  # Probabilidad de ser depresión\n",
        "else:\n",
        "    # Hay dos probabilidades en proba_prediction (clases binarias)\n",
        "    control_prob = 1 - proba_prediction[0][0]  # Probabilidad de ser control\n",
        "    depresion_prob = proba_prediction[0][0]  # Probabilidad de ser depresión\n",
        "\n",
        "# Las probabilidades de clase están en 'control_prob' y 'depresion_prob'\n",
        "\n",
        "# Imprimir el resultado basado en las probabilidades\n",
        "print(new_tweet)\n",
        "print('------------------------------------------------------------------')\n",
        "if depresion_prob > control_prob:\n",
        "    print(\"Este tweet es de depresión\")\n",
        "    print(\"Probabilidad de que el tweet sea de depresión: {:.2f}%\".format(depresion_prob * 100))\n",
        "else:\n",
        "    print(\"Este tweet No es de depresión\")\n",
        "    print(\"Probabilidad de que el tweet no sea de depresión: {:.2f}%\".format(control_prob * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT7DaY5CBOS_",
        "outputId": "997e3cd1-3bcb-4549-bf7b-5990a858b29e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n",
            "Que feo cuando te dicen un comentario y vos sabes que te duele cuando sentis ese nudo en la garganta y esas ganas de llorar\n",
            "------------------------------------------------------------------\n",
            "Este tweet es de depresión\n",
            "Probabilidad de que el tweet sea de depresión: 86.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "en compración con la implementación de la tecnica de la BoW y TIDF la red neuronal puedo entrenar con el conjunto de datos completo ya que al no ser un matriz dispersa ya que cada palabra es representada por un vector de 300 dimenciones la matriz resultante no consumir tanto requesitos computacionales, tambien la configuración de la red neuronal aumento el numero de neutoran de las capas ocultas, el numero de lotes y el numero de epoca resultando a un entrenamiento sastifactorio.\n",
        "\n",
        "Además, se observa que la caracterización de palabras con la tecnica de word embedding es un buen metodo ya que no crea vectores dispersos y encompración a los vectores de BOW y TFIDF que las palabras estan separadad a la misma distancia perdiendo con esto el valor semantico de las palabras en el conjunto de entrenamiento, mientras que los word embedding tiene  en cuenta el valor semantico de las palabras ya que dependiendo del conjuto de datos y del modelo preentrenado las palabras estan más cercas de unas dependiendo del contexto.\n",
        "\n",
        "al implementar un modelo preentreado como Word2Vec con millones de palabras, este modelo de forma no supervisada encuentra patrones internos y agrupando cierta palabras entre más similitudes tendan dentro del contento entreano de la base de datos obteniendo un conjuto de entrenamiento valioso ya que tiene en cuenta el contexto de la base datos a la hora de crear el arreglo vectorial para el entrenamiento del modelo.\n",
        "\n",
        "una desventanja que meneja la implementación de este modelo es que al crear un arreglo vectorial de cada palabra presente el vocabulario de entrenamiento se crea matrices muy grandes y complejas haciendo que el proceso de entrenamiento sea mucho más complejo y demorado."
      ],
      "metadata": {
        "id": "hmawcOn_kQrx"
      }
    }
  ]
}